{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "import pyproj\n",
    "# from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder.getOrCreate()\n",
    "from IPython.display import display\n",
    "import zipfile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nombres y Direcciones particulares de cada caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirección donde se ubican los archivos que se cargarán\n",
    "# path_case='A:/CentrodeEnergia/PLP20230104/OPLP20230104/data/'\n",
    "path_case = 'C:/Users/nicol/Documents/CentrodeEnergia/data-set-plexo/'\n",
    "# path_case='C:/Users/Lenovo/Documents/Work/Practica_II/Plexos/'\n",
    "# Nombre que tendrá el caso\n",
    "name_Case='PLEXOS'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "remotedesk=False\n",
    "\n",
    "if remotedesk:\n",
    "    path_data='C:/Users/Centro/Documents/DataPLP/'\n",
    "else:\n",
    "    path_data=path_case"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barra import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plpbar=pd.read_csv(path_data+'plpbar.csv')\n",
    "plpbar.columns=[\"Hidro\",\"time\",\"TipoEtapa\",\"id\",\"BarName\",\"CMgBar\",\"DemBarP\",\"DemBarE\",\"PerBarP\",\"PerBarE\",\"BarRetP\",\"BarRetE\"]\n",
    "plpbar['BarName']=plpbar['BarName'].str.replace(\" \",\"\")\n",
    "plpbar[\"Hidro\"] = plpbar[\"Hidro\"].str.replace(\" \", \"\")\n",
    "\n",
    "indexbus=plpbar[['id','BarName']].drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "ubibar=pd.read_csv(path_data+'ubibar.csv',sep=';',encoding='utf-8-sig')\n",
    "ubibar=ubibar.drop('ID',axis=1)\n",
    "ubibar['LATITUD']=ubibar['LATITUD'].apply(lambda x:x.replace(',','.')).apply(float)\n",
    "ubibar['LONGITUD']=ubibar['LONGITUD'].apply(lambda x:x.replace(',','.')).apply(float)\n",
    "ubibar.columns=[\"BarName\",\"latitud\",\"longitud\"]\n",
    "ubibar['BarName']=ubibar['BarName'].str.replace(\" \",\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plpcen=pd.read_csv(path_data+'plpcen.csv')\n",
    "plpcen.columns=[\"Hidro\",\"time\",\"TipoEtapa\",\"id\",\"CenName\",\"tipo\",\"bus_id\",\"BarName\",\"CenQgen\",\"CenPgen\",\"CenEgen\",\"CenInyP\",\"CenInyE\",\"CenRen\",\"CenCVar\",\"CenCostOp\",\"CenPMax\"]\n",
    "plpcen['CenName']=plpcen[\"CenName\"].str.replace(\" \",\"\")\n",
    "plpcen=plpcen.drop([\"CenEgen\",\"CenInyP\",\"CenInyE\",\"CenRen\",\"CenCostOp\",\"CenPMax\"],axis=1)\n",
    "plpcen[\"Hidro\"] = plpcen[\"Hidro\"].str.replace(\" \", \"\")\n",
    "plpcen['tipo']='otros'\n",
    "\n",
    "indexcen=plpcen[['id','CenName','tipo','bus_id']].drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "centralsinfo=pd.read_csv(path_data+'centralesinfo.csv',sep=';',encoding='utf-8-sig')\n",
    "centralsinfo.columns=['id','CenName','type','CVar','effinciency','bus_id','serie_hidro_gen','serie_hidro_ver','min_power','max_power',\"VembIn\",\"VembFin\",\"VembMin\",\"VembMax\",\"cotaMínima\"]\n",
    "\n",
    "cols = ['min_power', 'max_power', 'effinciency', 'CVar', 'VembIn', 'VembFin', 'VembMin', 'VembMax', 'cotaMínima']\n",
    "centralsinfo['CenName'] = centralsinfo[\"CenName\"].str.replace(\" \", \"\")\n",
    "for col in cols:\n",
    "    centralsinfo[col] = centralsinfo[col].replace(\",\", \".\", regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hydric_adicional = pd.read_csv(path_data+'hydric_adicional.csv',sep=\";\")\n",
    "\n",
    "tiposcentrales=pd.read_csv(path_data+'centralestype.csv',encoding='latin-1').rename(columns={'cen_name':'CenName'})\n",
    "typecentrals=indexcen.merge(tiposcentrales,on='CenName')\n",
    "\n",
    "for x in range(len(indexcen['id'])):\n",
    "    tipo=typecentrals[typecentrals['CenName']==indexcen['CenName'][x]]['cen_type'].values\n",
    "    \n",
    "    if len(tipo)>0:\n",
    "        plpcen.loc[plpcen['id'] == indexcen['id'][x], 'tipo'] = tipo[0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineas import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plplin=pd.read_csv(path_data+'plplin.csv')\n",
    "# Cambiando los nombres de las columnas\n",
    "plplin.columns=[\"Hidro\",\"time\",\"TipoEtapa\",\"id\",\"LinName\",\"bus_a\",\"bus_b\",\"LinFluP\",\"LinFluE\",\"capacity\",\"LinUso\",\"LinPerP\",\"LinPerE\",\"LinPer2P\",\"LinPer2E\",\"LinITP\",\"LinITE\"]\n",
    "plplin['LinName']=plplin['LinName'].str.replace(\" \",\"\")\n",
    "plplin[\"Hidro\"] = plplin[\"Hidro\"].str.replace(\" \", \"\")\n",
    "\n",
    "indexlin=plplin[['id','LinName',\"bus_a\",\"bus_b\"]].drop_duplicates(keep=\"first\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "linesinfo=pd.read_csv(path_data+'linesinfo.csv',sep=';')\n",
    "linesinfo.columns=[\"id\",\"LinName\",\"bus_a\",\"bus_b\",\"max_flow_a_b\",\"max_flow_b_a\",\"voltage\",\"r\",\"x\",\"segments\",\"active\"]\n",
    "linesinfo['LinName']=linesinfo['LinName'].str.replace(\" \",\"\")\n",
    "linesinfo['max_flow_a_b']=(linesinfo[\"max_flow_a_b\"].apply(str)).apply(lambda x:x.replace(',','.')).apply(float)\n",
    "linesinfo['max_flow_b_a']=(linesinfo['max_flow_b_a'].apply(str)).apply(lambda x:x.replace(',','.')).apply(float)\n",
    "linesinfo['r']=(linesinfo['r'].apply(str)).apply(lambda x:x.replace(',','.')).apply(float)\n",
    "linesinfo['x']=(linesinfo['x'].apply(str)).apply(lambda x:x.replace(',','.')).apply(float)\n",
    "\n",
    "linesfinal=indexlin.drop(['id','bus_a','bus_b'],axis=1).merge(linesinfo,on='LinName')\n",
    "linesfinal['id']=(linesfinal['id']).apply(int)\n",
    "linesfinal.sort_values(\"id\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reservoirs Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reservoirs = pd.read_csv(path_data+'plpemb.csv')\n",
    "# reservoirs.rename(columns={'Bloque': 'time', 'EmbNum': 'id', 'EmbNom': 'EmbName'}, inplace=True)\n",
    "# reservoirs['EmbName']=reservoirs['EmbName'].str.replace(\" \",\"\")\n",
    "# reservoirs['Hidro']=reservoirs['Hidro'].str.replace(\" \",\"\")\n",
    "\n",
    "# indexres = reservoirs[['id','EmbName']].drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "# junctionsinfo=centralsinfo[centralsinfo['type'].isin([\"E\",'S','R'])].reset_index(drop=True)\n",
    "# reservoirsinfo=centralsinfo[centralsinfo['type'].isin([\"E\"])].reset_index(drop=True)\n",
    "# reservoirsinfo.rename(columns={'CenName':'EmbName'}, inplace=True)\n",
    "\n",
    "# for i, emb_name in enumerate(reservoirsinfo['EmbName']):\n",
    "#     if emb_name in indexres['EmbName'].values:\n",
    "#         idx = indexres.index[indexres['EmbName'] == emb_name][0]\n",
    "#         reservoirsinfo.at[i, 'id'] = indexres.at[idx, 'id']\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indhor import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indhor = pd.read_csv(path_data+'indhor.csv',encoding='latin-1')\n",
    "indhor = pd.read_csv(path_data+'indhor.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando directorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre data\n",
    "namedata=name_Case\n",
    "electricTopology=namedata+'/Topology/Electric'\n",
    "hydricTopology=namedata+'/Topology/Hydric'\n",
    "\n",
    "os.makedirs(electricTopology,exist_ok=True)\n",
    "os.makedirs(hydricTopology,exist_ok=True)\n",
    "\n",
    "\n",
    "hidrolist=plpbar['Hidro'].unique()\n",
    "busscenariolist=[]\n",
    "centralscenariolist=[]\n",
    "linescenariolist=[]\n",
    "reservoirscenariolist=[]\n",
    "for hidronum in range(len(hidrolist)):\n",
    "\t# Creamos los directorios\n",
    "\tbusscenario= namedata+f'/Scenarios/{hidronum+1}/Bus'\n",
    "\tcentralscenario=namedata+f'/Scenarios/{hidronum+1}/Centrals'\n",
    "\tlinescenario=namedata+f'/Scenarios/{hidronum+1}/Lines'\n",
    "\treservoirscenario=namedata+f'/Scenarios/{hidronum+1}/Reservoirs'\n",
    "\n",
    "\tos.makedirs(busscenario,exist_ok=True)\n",
    "\tbusscenariolist.append(busscenario)\n",
    "\n",
    "\tos.makedirs(centralscenario,exist_ok=True)\n",
    "\tcentralscenariolist.append(centralscenario)\n",
    "\n",
    "\tos.makedirs(linescenario,exist_ok=True)\n",
    "\tlinescenariolist.append(linescenario)\n",
    "\n",
    "\tos.makedirs(reservoirscenario,exist_ok=True)\n",
    "\treservoirscenariolist.append(reservoirscenario)\n",
    "\n",
    "marginal_cost_path=namedata+f'/Scenarios/Marginal_cost_percentil'\n",
    "line_flow_percentil_path=namedata+f'/Scenarios/Flow_Line_percentil'\n",
    "generation_sistem_path=namedata+f'/Scenarios/Generation_system'\n",
    "os.makedirs(marginal_cost_path,exist_ok=True)\n",
    "os.makedirs(line_flow_percentil_path,exist_ok=True)\n",
    "os.makedirs(generation_sistem_path,exist_ok=True)\n",
    "hydrofile = [x for x in range(1,len(hidrolist)+1)]\n",
    "\n",
    "with open( namedata+'/Scenarios/hydrologies.json', 'w') as f:\n",
    "  json.dump(hydrofile, f)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables indicadoras de cantidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de horas de bloques temporales del proyecto\n",
    "time=plplin['time'].max()\n",
    "\n",
    "# Número de barras\n",
    "nbus=len(indexbus['id'])\n",
    "lbus=list(indexbus['id'])\n",
    "\n",
    "# Número de generadores\n",
    "ngen=len(indexcen['id'])\n",
    "\n",
    "# Número de lineas\n",
    "nlin=len(indexlin['id'])\n",
    "\n",
    "# Número de Reservoirs\n",
    "# nres = len(reservoirs['EmbName'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed de lineas previcionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[200, 201], [137, 139]]\n"
     ]
    }
   ],
   "source": [
    "filtered_lines = linesfinal[linesfinal.duplicated(subset=['bus_a', 'bus_b'], keep=False)]\n",
    "\n",
    "groups = filtered_lines.groupby(['bus_a', 'bus_b'])['id']\n",
    "\n",
    "parallel_lines = []\n",
    "for _, group in groups:\n",
    "    parallel_lines.append(group.values.tolist())\n",
    "\n",
    "print(parallel_lines)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnesfinal_aux = linesfinal.copy()\n",
    "for sublist in parallel_lines:\n",
    "    first_element = sublist[0]\n",
    "    suma_maxab=0\n",
    "    suma_maxba=0\n",
    "    linesfinal.loc[linesfinal['id'] == first_element, 'LinName'] += \"- mixed\"\n",
    "    for element in sublist:\n",
    "        if linesfinal.loc[linesfinal['id'] == element, 'active'].values[0] == 1: \n",
    "            suma_maxab+=linesfinal.loc[linesfinal['id'] == element, 'max_flow_a_b'].values[0]\n",
    "            suma_maxba+=linesfinal.loc[linesfinal['id'] == element, 'max_flow_b_a'].values[0]\n",
    "            linesfinal.loc[linesfinal['id'] == element, 'active'] = 0\n",
    "    linesfinal.loc[linesfinal['id'] == first_element, 'active'] = 1\n",
    "    linesfinal.loc[linesfinal['id'] == first_element, 'max_flow_a_b']=suma_maxab\n",
    "    linesfinal.loc[linesfinal['id'] == first_element, 'max_flow_b_a']=suma_maxba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array con todos los primeros elementos de las listas en 'parallel_lines'\n",
    "first_elements = np.array([x[0] for x in parallel_lines])\n",
    "plplin_copy = plplin.copy()\n",
    "# Añadir \"- mixed\" al final de los valores en 'LinName' donde 'id' hace match con el primer valor de cada lista en 'parallel_lines'\n",
    "plplin_copy['LinName'] = np.where(plplin_copy['id'].isin(first_elements), plplin_copy['LinName'] + '- mixed', plplin_copy['LinName'])\n",
    "\n",
    "plplin_copy = pd.merge(plplin_copy, lnesfinal_aux[['id', 'active']], on='id', how='left')\n",
    "\n",
    "# Crear un nuevo dataframe donde cada fila es una lista en 'parallel_lines'\n",
    "parallel_df = plplin_copy[plplin_copy['id'].isin([item for sublist in parallel_lines for item in sublist])].copy()\n",
    "\n",
    "# Creamos una columna \"parallel_id\" que tenga el primer id de la línea paralela correspondiente para cada fila.\n",
    "parallel_dict = {id_par: par[0] for par in parallel_lines for id_par in par}\n",
    "parallel_df['parallel_id'] = parallel_df['id'].map(parallel_dict)\n",
    "\n",
    "# Ahora podemos agrupar por 'Hidro', 'time' y 'parallel_id', y sumar 'LinFluP' y 'capacity' dentro de cada grupo.\n",
    "grouped_df = parallel_df[parallel_df['active'] == 1].groupby(['Hidro', 'time', 'parallel_id'])[['LinFluP', 'capacity']].sum().reset_index()\n",
    "\n",
    "# Primero, fusionamos 'parallel_df' con 'grouped_df'.\n",
    "result = pd.merge(parallel_df, grouped_df, on=['Hidro', 'time', 'parallel_id'], how='left', suffixes=('', '_sum'))\n",
    "\n",
    "# Ahora, reemplazamos los valores de 'LinFluP' y 'capacity' con los de 'LinFluP_sum' y 'capacity_sum' solo para las filas donde 'id' es igual a 'parallel_id'.\n",
    "result.loc[result['id'] == result['parallel_id'], 'LinFluP'] = result['LinFluP_sum']\n",
    "result.loc[result['id'] == result['parallel_id'], 'capacity'] = result['capacity_sum']\n",
    "\n",
    "# Finalmente, eliminamos las columnas 'LinFluP_sum' y 'capacity_sum' ya que no las necesitamos más.\n",
    "result = result.drop(columns=['LinFluP_sum', 'capacity_sum'])\n",
    "\n",
    "# Si también quieres eliminar la columna 'parallel_id', puedes hacerlo así:\n",
    "result = result.drop(columns=['parallel_id'])\n",
    "\n",
    "# Asignar los valores calculados en 'result' a las filas correspondientes en 'plplin_copy'\n",
    "plplin_copy.set_index(['Hidro', 'time', 'id'], inplace=True)\n",
    "result.set_index(['Hidro', 'time', 'id'], inplace=True)\n",
    "\n",
    "plplin_copy.update(result[['LinFluP', 'capacity']])\n",
    "\n",
    "# Restablecer el índice\n",
    "plplin_copy.reset_index(inplace=True)\n",
    "\n",
    "plplin = plplin_copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función generadora de latitudes y longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aleatory_direction():\n",
    "    latitud=-random.uniform(10, 85)\n",
    "    longitud=-random.uniform(10, 85)\n",
    "    return latitud,longitud\n",
    "\n",
    "def LatLon_To_XY(Lat,Lon):\n",
    "  B = pyproj.Transformer.from_crs(4326,20049) #WGS84->EPSG:20049 (Chile 2021/UTM zone 19S)\n",
    "  UTMx, UTMy = B.transform(Lat,Lon)\n",
    "  return UTMx, UTMy\n",
    "\n",
    "def XY_To_LatLon(x,y):\n",
    "  B = pyproj.Transformer.from_crs(20049,4326)\n",
    "  Lat, Lon = B.transform(x,y)\n",
    "  return Lat, Lon\n",
    "\n",
    "def valorXY(LatP, LonP, scale):\n",
    "  A = LatLon_To_XY(LatP, LonP)\n",
    "  X,Y = A[0]*scale, A[1]*scale\n",
    "  return Y,X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloques a Fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indhor2=indhor.drop('Hora',axis=1).groupby(['Año','Mes'])\n",
    "indhor2=indhor.drop('Hora',axis=1).groupby(['Dia','Mes'])\n",
    "\n",
    "indhorlist=[]\n",
    "for x in indhor2:\n",
    "    indhorlist.append([str(x[1]['Bloque'].min()),str(x[1]['Bloque'].max()),str(x[0])])\n",
    "with open( namedata+'/Scenarios/indhor.json', 'w') as f:\n",
    "  json.dump(indhorlist, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación por Sistema por Hidrología"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim1 lista\n"
     ]
    }
   ],
   "source": [
    "typegenlist=typecentrals.cen_type.unique()\n",
    "for i,hydro in enumerate(hidrolist):\n",
    "    print(hydro+\" lista\")\n",
    "    dic_type_gen={}\n",
    "    auxdf = plpcen[plpcen['Hidro']==hydro]\n",
    "    auxdf=auxdf.groupby(['tipo','time'])['CenPgen'].sum().reset_index().groupby('tipo')\n",
    "    for group in auxdf:\n",
    "        tipo = group[0]\n",
    "        df_tipo = group[1]\n",
    "        dic_type_gen[tipo] = [row for row in df_tipo[['time', 'CenPgen']].to_dict(orient='records')]\n",
    "    \n",
    "    with open(generation_sistem_path+f'/generation_system_{i+1}.json', 'w') as f:\n",
    "        json.dump(dic_type_gen, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentiles Costo Marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando datos de AltoNorte110 [1/214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando datos de Andes220 [2/214]\n",
      "Procesando datos de Andes345 [3/214]\n",
      "Procesando datos de Angamos220 [4/214]\n",
      "Procesando datos de Antofagasta110 [5/214]\n",
      "Procesando datos de Arica066 [6/214]\n",
      "Procesando datos de Atacama220_BP1 [7/214]\n",
      "Procesando datos de Barriles220 [8/214]\n",
      "Procesando datos de Cachiyuyal220 [9/214]\n",
      "Procesando datos de Capricornio110 [10/214]\n",
      "Procesando datos de Capricornio220 [11/214]\n",
      "Procesando datos de Cardones110 [12/214]\n",
      "Procesando datos de Cardones220 [13/214]\n",
      "Procesando datos de Chacaya220 [14/214]\n",
      "Procesando datos de Chuquicamata100 [15/214]\n",
      "Procesando datos de Chuquicamata220 [16/214]\n",
      "Procesando datos de Cochrane220 [17/214]\n",
      "Procesando datos de Collahuasi220 [18/214]\n",
      "Procesando datos de Conchi220 [19/214]\n",
      "Procesando datos de Condores220 [20/214]\n",
      "Procesando datos de CPinto220 [21/214]\n",
      "Procesando datos de Crucero220 [22/214]\n",
      "Procesando datos de Cumbres500 [23/214]\n",
      "Procesando datos de DAlmagro110 [24/214]\n",
      "Procesando datos de DAlmagro220 [25/214]\n",
      "Procesando datos de DArica066 [26/214]\n",
      "Procesando datos de Desalant110 [27/214]\n",
      "Procesando datos de Domeyko220 [28/214]\n",
      "Procesando datos de DonaCarmen220 [29/214]\n",
      "Procesando datos de DonGoyo220 [30/214]\n",
      "Procesando datos de DonHector220 [31/214]\n",
      "Procesando datos de ElCobre220 [32/214]\n",
      "Procesando datos de ElLoa220 [33/214]\n",
      "Procesando datos de ElNegro110 [34/214]\n",
      "Procesando datos de ElPenon110 [35/214]\n",
      "Procesando datos de ElTesoro220 [36/214]\n",
      "Procesando datos de Esmeralda110 [37/214]\n",
      "Procesando datos de Esmeralda220 [38/214]\n",
      "Procesando datos de Esperanza220 [39/214]\n",
      "Procesando datos de Francisco220 [40/214]\n",
      "Procesando datos de Guacolda220 [41/214]\n",
      "Procesando datos de Huasco110 [42/214]\n",
      "Procesando datos de Kapatur220_BP1 [43/214]\n",
      "Procesando datos de Laberinto220 [44/214]\n",
      "Procesando datos de LaCebada220 [45/214]\n",
      "Procesando datos de LaCruz220 [46/214]\n",
      "Procesando datos de Lagunas220 [47/214]\n",
      "Procesando datos de LaNegra110 [48/214]\n",
      "Procesando datos de LosChangos220 [49/214]\n",
      "Procesando datos de LosChangos500 [50/214]\n",
      "Procesando datos de LPalmas220 [51/214]\n",
      "Procesando datos de LVilos220 [52/214]\n",
      "Procesando datos de Maitencillo110 [53/214]\n",
      "Procesando datos de Maitencillo220 [54/214]\n",
      "Procesando datos de Mantos220 [55/214]\n",
      "Procesando datos de MariaElena220 [56/214]\n",
      "Procesando datos de Mejillones110 [57/214]\n",
      "Procesando datos de Mejillones220 [58/214]\n",
      "Procesando datos de Miraje220 [59/214]\n",
      "Procesando datos de MRedondo220 [60/214]\n",
      "Procesando datos de Norgener220 [61/214]\n",
      "Procesando datos de NvaCardones500 [62/214]\n",
      "Procesando datos de NvaMaitencillo500 [63/214]\n",
      "Procesando datos de NvaPAzucar500 [64/214]\n",
      "Procesando datos de NvaVictoria220 [65/214]\n",
      "Procesando datos de NvaZaldivar220 [66/214]\n",
      "Procesando datos de Oeste220 [67/214]\n",
      "Procesando datos de Ohiggins220_BP1 [68/214]\n",
      "Procesando datos de Palestina220 [69/214]\n",
      "Procesando datos de PAlmonte110 [70/214]\n",
      "Procesando datos de PAlmonte220 [71/214]\n",
      "Procesando datos de Pampa110 [72/214]\n",
      "Procesando datos de Paposo220 [73/214]\n",
      "Procesando datos de PAzucar110 [74/214]\n",
      "Procesando datos de PAzucar220 [75/214]\n",
      "Procesando datos de PColorada220 [76/214]\n",
      "Procesando datos de Portada110 [77/214]\n",
      "Procesando datos de PuntaSierra220 [78/214]\n",
      "Procesando datos de S-AA100 [79/214]\n",
      "Procesando datos de Salar110 [80/214]\n",
      "Procesando datos de Salar220 [81/214]\n",
      "Procesando datos de Salta345 [82/214]\n",
      "Procesando datos de S-Km6100 [83/214]\n",
      "Procesando datos de Talinay220 [84/214]\n",
      "Procesando datos de Tamaya110 [85/214]\n",
      "Procesando datos de Tarapaca220 [86/214]\n",
      "Procesando datos de TO_Enlace220 [87/214]\n",
      "Procesando datos de Tocopilla110 [88/214]\n",
      "Procesando datos de Tocopilla220_BP1 [89/214]\n",
      "Procesando datos de AJahuel110 [90/214]\n",
      "Procesando datos de AJahuel154 [91/214]\n",
      "Procesando datos de AJahuel220 [92/214]\n",
      "Procesando datos de AJahuel500 [93/214]\n",
      "Procesando datos de Alfalfal220 [94/214]\n",
      "Procesando datos de Almendros110 [95/214]\n",
      "Procesando datos de Almendros220 [96/214]\n",
      "Procesando datos de AMelipilla220 [97/214]\n",
      "Procesando datos de Ancoa220 [98/214]\n",
      "Procesando datos de Ancoa500 [99/214]\n",
      "Procesando datos de Angostura220 [100/214]\n",
      "Procesando datos de Antuco220 [101/214]\n",
      "Procesando datos de Apoquindo110 [102/214]\n",
      "Procesando datos de ASanta110 [103/214]\n",
      "Procesando datos de ASanta220 [104/214]\n",
      "Procesando datos de Batuco110 [105/214]\n",
      "Procesando datos de Bocamina154 [106/214]\n",
      "Procesando datos de Buin110 [107/214]\n",
      "Procesando datos de Candelaria220 [108/214]\n",
      "Procesando datos de Canutillar220 [109/214]\n",
      "Procesando datos de Cautin220 [110/214]\n",
      "Procesando datos de Charrua066 [111/214]\n",
      "Procesando datos de Charrua154 [112/214]\n",
      "Procesando datos de Charrua220 [113/214]\n",
      "Procesando datos de Charrua500 [114/214]\n",
      "Procesando datos de Chena110 [115/214]\n",
      "Procesando datos de Chena220 [116/214]\n",
      "Procesando datos de Chillan154 [117/214]\n",
      "Procesando datos de Chiloe110 [118/214]\n",
      "Procesando datos de Cholguan066 [119/214]\n",
      "Procesando datos de Cholguan220 [120/214]\n",
      "Procesando datos de Chonchi110 [121/214]\n",
      "Procesando datos de Cipreses154 [122/214]\n",
      "Procesando datos de Ciruelos220 [123/214]\n",
      "Procesando datos de CNavia110 [124/214]\n",
      "Procesando datos de CNavia220 [125/214]\n",
      "Procesando datos de CNavia220_Desf [126/214]\n",
      "Procesando datos de Colbun220 [127/214]\n",
      "Procesando datos de Concepcion066 [128/214]\n",
      "Procesando datos de Concepcion154 [129/214]\n",
      "Procesando datos de Constitucion066 [130/214]\n",
      "Procesando datos de Coronel066 [131/214]\n",
      "Procesando datos de Coronel154 [132/214]\n",
      "Procesando datos de Degan110 [133/214]\n",
      "Procesando datos de Duqueco220 [134/214]\n",
      "Procesando datos de ElSalto110 [135/214]\n",
      "Procesando datos de EntreRios220 [136/214]\n",
      "Procesando datos de EntreRios500 [137/214]\n",
      "Procesando datos de Florida110 [138/214]\n",
      "Procesando datos de Fopaco154 [139/214]\n",
      "Procesando datos de Horcones066 [140/214]\n",
      "Procesando datos de Hualpen154 [141/214]\n",
      "Procesando datos de Hualpen220 [142/214]\n",
      "Procesando datos de Itahue154 [143/214]\n",
      "Procesando datos de Lagunillas154 [144/214]\n",
      "Procesando datos de Lagunillas220 [145/214]\n",
      "Procesando datos de Lautaro066 [146/214]\n",
      "Procesando datos de Linares154 [147/214]\n",
      "Procesando datos de LoAguirre220 [148/214]\n",
      "Procesando datos de LoAguirre500 [149/214]\n",
      "Procesando datos de LoEspejo110 [150/214]\n",
      "Procesando datos de LVegas110 [151/214]\n",
      "Procesando datos de LVegas110_exp [152/214]\n",
      "Procesando datos de Malloa154 [153/214]\n",
      "Procesando datos de Mapal154 [154/214]\n",
      "Procesando datos de Maule154 [155/214]\n",
      "Procesando datos de Miraflores110 [156/214]\n",
      "Procesando datos de Molinos110 [157/214]\n",
      "Procesando datos de Mulchen220 [158/214]\n",
      "Procesando datos de Nogales220 [159/214]\n",
      "Procesando datos de Ochagavia110 [160/214]\n",
      "Procesando datos de Pachacama110 [161/214]\n",
      "Procesando datos de Paine154 [162/214]\n",
      "Procesando datos de PAltoCmpc110 [163/214]\n",
      "Procesando datos de Pangue220 [164/214]\n",
      "Procesando datos de Parral154 [165/214]\n",
      "Procesando datos de PCortes154 [166/214]\n",
      "Procesando datos de Pehuenche220 [167/214]\n",
      "Procesando datos de Petroquim154 [168/214]\n",
      "Procesando datos de Pichirrahue220 [169/214]\n",
      "Procesando datos de Pichirropulli220 [170/214]\n",
      "Procesando datos de Pid-Pid110 [171/214]\n",
      "Procesando datos de Pillanlelbun066 [172/214]\n",
      "Procesando datos de PMontt220 [173/214]\n",
      "Procesando datos de PNegro220 [174/214]\n",
      "Procesando datos de Polpaico220 [175/214]\n",
      "Procesando datos de Polpaico500 [176/214]\n",
      "Procesando datos de PPeuco110 [177/214]\n",
      "Procesando datos de Quillota110 [178/214]\n",
      "Procesando datos de Quillota220 [179/214]\n",
      "Procesando datos de Quintero220 [180/214]\n",
      "Procesando datos de Rahue220 [181/214]\n",
      "Procesando datos de Ralco220 [182/214]\n",
      "Procesando datos de Rancagua154 [183/214]\n",
      "Procesando datos de Rapel220 [184/214]\n",
      "Procesando datos de Renca110 [185/214]\n",
      "Procesando datos de RioTolten220 [186/214]\n",
      "Procesando datos de Rucue220 [187/214]\n",
      "Procesando datos de SanLuis220 [188/214]\n",
      "Procesando datos de SantaElvira066 [189/214]\n",
      "Procesando datos de SantaMaria220 [190/214]\n",
      "Procesando datos de SantaMarta220 [191/214]\n",
      "Procesando datos de Sauzal110_BP1 [192/214]\n",
      "Procesando datos de Sauzal110_BP2 [193/214]\n",
      "Procesando datos de Sauzal154 [194/214]\n",
      "Procesando datos de SCristobal110 [195/214]\n",
      "Procesando datos de SFcoMost066 [196/214]\n",
      "Procesando datos de SJavier066 [197/214]\n",
      "Procesando datos de SMiguel066 [198/214]\n",
      "Procesando datos de StaRosa110 [199/214]\n",
      "Procesando datos de SVicente154 [200/214]\n",
      "Procesando datos de Talca066 [201/214]\n",
      "Procesando datos de Temuco066 [202/214]\n",
      "Procesando datos de Temuco220 [203/214]\n",
      "Procesando datos de Teno154 [204/214]\n",
      "Procesando datos de Tilcoco154 [205/214]\n",
      "Procesando datos de Tineo220 [206/214]\n",
      "Procesando datos de Tinguiririca154 [207/214]\n",
      "Procesando datos de Torquemada110 [208/214]\n",
      "Procesando datos de Trupan220 [209/214]\n",
      "Procesando datos de Tuniche154_I [210/214]\n",
      "Procesando datos de Tuniche154_II [211/214]\n",
      "Procesando datos de Valdivia220 [212/214]\n",
      "Procesando datos de Ventanas110 [213/214]\n",
      "Procesando datos de Ventanas220 [214/214]\n"
     ]
    }
   ],
   "source": [
    "def percentilCM():\n",
    "    datos_bar = plpbar[['Hidro', 'time','id', 'BarName', 'CMgBar']]\n",
    "    lista_bar = datos_bar.BarName.unique()\n",
    "\n",
    "    i=1\n",
    "    for barra in lista_bar:\n",
    "        print(f'Procesando datos de {barra} [{i}/{len(lista_bar)}]')\n",
    "        data_barraTx = datos_bar.loc[(datos_bar.BarName == barra)]\n",
    "        idbar=data_barraTx['id'].unique()[0]\n",
    "        data_barraTx = data_barraTx[~(data_barraTx['Hidro'] == 'MEDIA')]\n",
    "        Promedio = data_barraTx[['time','CMgBar']]\n",
    "        xy =Promedio.groupby(['time']).mean()\n",
    "        \n",
    "        data_barraTx = data_barraTx.groupby(['time']).agg(perc0=('CMgBar', lambda x: x.quantile(0.0)),\n",
    "                                                                perc20=(\n",
    "                                                                    'CMgBar', lambda x: x.quantile(0.2)),\n",
    "                                                                perc80=(\n",
    "                                                                    'CMgBar', lambda x: x.quantile(0.8)),\n",
    "                                                                perc100=('CMgBar', lambda x: x.quantile(1)))\n",
    "\n",
    "        data_barraTx['promedio'] = xy\n",
    "        data_barraTx = data_barraTx.assign(name=barra)\n",
    "        data_barraTx = data_barraTx.assign(id=idbar)\n",
    "        data_barraTx.reset_index(inplace=True)\n",
    "        data_barraTx=data_barraTx[['id','time','name','perc0','perc20','perc80','perc100','promedio']]\n",
    "        data_barraTx.to_json(marginal_cost_path+f\"/bus_{idbar}.json\",orient='records')\n",
    "        i=i+1\n",
    "\n",
    "\n",
    "percentilCM()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentiles Flujos de Lineas de Transmisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando datos de AJahuel110->Sauzal110_BP1 [1/282]\n",
      "Procesando datos de AJahuel154->Paine154 [2/282]\n",
      "Procesando datos de AJahuel154->Tuniche154_II [3/282]\n",
      "Procesando datos de AJahuel220->AJahuel110 [4/282]\n",
      "Procesando datos de AJahuel220->AJahuel154 [5/282]\n",
      "Procesando datos de AJahuel220->Buin110 [6/282]\n",
      "Procesando datos de AJahuel220->Chena220 [7/282]\n",
      "Procesando datos de AJahuel220->PAltoCmpc110 [8/282]\n",
      "Procesando datos de AJahuel220->SantaMarta220 [9/282]\n",
      "Procesando datos de AJahuel500->AJahuel220 [10/282]\n",
      "Procesando datos de Alfalfal220->Almendros220 [11/282]\n",
      "Procesando datos de Almendros110->Apoquindo110 [12/282]\n",
      "Procesando datos de Almendros220->AJahuel220 [13/282]\n",
      "Procesando datos de Almendros220->Almendros110 [14/282]\n",
      "Procesando datos de AMelipill220->LoAguirre220 [15/282]\n",
      "Procesando datos de Ancoa220->Itahue154 [16/282]\n",
      "Procesando datos de Ancoa500->AJahuel500 [17/282]\n",
      "Procesando datos de Ancoa500->Ancoa220 [18/282]\n",
      "Procesando datos de Andes220->Oeste220 [19/282]\n",
      "Procesando datos de Andes345->Andes220 [20/282]\n",
      "Procesando datos de Angamos220->Kapatur220 [21/282]\n",
      "Procesando datos de Angostura220->Mulchen220 [22/282]\n",
      "Procesando datos de Antofag110->Desalant110 [23/282]\n",
      "Procesando datos de Antuco220->Charrua220 [24/282]\n",
      "Procesando datos de Antuco220->Trupan220 [25/282]\n",
      "Procesando datos de Apoquindo110->ElSalto110 [26/282]\n",
      "Procesando datos de Arica066->PAlmonte110 [27/282]\n",
      "Procesando datos de ASanta110->Mirafl110 [28/282]\n",
      "Procesando datos de ASanta220->ASanta110 [29/282]\n",
      "Procesando datos de Atacama220->OHiggins220 [30/282]\n",
      "Procesando datos de Batuco110->PPeuco110_I [31/282]\n",
      "Procesando datos de Bocamina154->Coronel154 [32/282]\n",
      "Procesando datos de Buin110->LoEspejo110 [33/282]\n",
      "Procesando datos de Cachiyuyal220->DAlmagro220 [34/282]\n",
      "Procesando datos de Candela220->AJahuel220 [35/282]\n",
      "Procesando datos de Canutilla220->PMontt220 [36/282]\n",
      "Procesando datos de Capricorn220->Capricorn110 [37/282]\n",
      "Procesando datos de Capricornio110->Antofag110 [38/282]\n",
      "Procesando datos de Capricornio110->ElNegro110 [39/282]\n",
      "Procesando datos de Capricornio110->LaNegra110 [40/282]\n",
      "Procesando datos de Capricornio220->Mantos220 [41/282]\n",
      "Procesando datos de Cardones220->Cardones110 [42/282]\n",
      "Procesando datos de Cardones220->CPinto220 [43/282]\n",
      "Procesando datos de Cautin220->RioTolten220 [44/282]\n",
      "Procesando datos de Chacaya220->Capricornio220 [45/282]\n",
      "Procesando datos de Chacaya220->ElCobre220 [46/282]\n",
      "Procesando datos de Chacaya220->Mejillones220 [47/282]\n",
      "Procesando datos de Charrua066->Cholguan066 [48/282]\n",
      "Procesando datos de Charrua154->Charrua066 [49/282]\n",
      "Procesando datos de Charrua154->Chillan154 [50/282]\n",
      "Procesando datos de Charrua154->Conce154 [51/282]\n",
      "Procesando datos de Charrua154->Parral154 [52/282]\n",
      "Procesando datos de Charrua220->Charrua154 [53/282]\n",
      "Procesando datos de Charrua220->Charrua500 [54/282]\n",
      "Procesando datos de Charrua220->Conce154 [55/282]\n",
      "Procesando datos de Charrua220->Duqueco220 [56/282]\n",
      "Procesando datos de Charrua220->EntreRios220 [57/282]\n",
      "Procesando datos de Charrua220->Hualpen220 [58/282]\n",
      "Procesando datos de Charrua220->Lagunillas220 [59/282]\n",
      "Procesando datos de Charrua220->Mulchen220 [60/282]\n",
      "Procesando datos de Charrua220->Ralco220 [61/282]\n",
      "Procesando datos de Charrua500->Ancoa500 [62/282]\n",
      "Procesando datos de Chena110->LoEspejo110 [63/282]\n",
      "Procesando datos de Chena220->Chena110 [64/282]\n",
      "Procesando datos de Chillan154->SantaElvira066 [65/282]\n",
      "Procesando datos de Chiloe110->Degan110 [66/282]\n",
      "Procesando datos de Chiloe110->Pid-Pid110 [67/282]\n",
      "Procesando datos de Cholguan220->Charrua220 [68/282]\n",
      "Procesando datos de Chuqui220->Chuqui100 [69/282]\n",
      "Procesando datos de Chuquicamata100->S-AA100 [70/282]\n",
      "Procesando datos de Chuquicamata100->S-Km6100 [71/282]\n",
      "Procesando datos de Cipreses154->Itahue154 [72/282]\n",
      "Procesando datos de Ciruelos220->Prropulli220 [73/282]\n",
      "Procesando datos de Ciruelos220->Valdivia220 [74/282]\n",
      "Procesando datos de CNavia110->Batuco110_I [75/282]\n",
      "Procesando datos de CNavia110->Chena110 [76/282]\n",
      "Procesando datos de CNavia110->LVegas110_exp [77/282]\n",
      "Procesando datos de CNavia220_Aux_D->Polpaico220 [78/282]\n",
      "Procesando datos de CNavia220->Chena220 [79/282]\n",
      "Procesando datos de CNavia220->CNavia110 [80/282]\n",
      "Procesando datos de CNavia220->CNavia220_Aux_D [81/282]\n",
      "Procesando datos de Cochrane220->Encuentro220 [82/282]\n",
      "Procesando datos de Colbun220->Ancoa220 [83/282]\n",
      "Procesando datos de Colbun220->PNegro220 [84/282]\n",
      "Procesando datos de Conce154->Conce066 [85/282]\n",
      "Procesando datos de Conce154->SVicente154 [86/282]\n",
      "Procesando datos de Coronel154->Coronel066 [87/282]\n",
      "Procesando datos de Coronel154->Horcones066 [88/282]\n",
      "Procesando datos de Coronel66->Conce066 [89/282]\n",
      "Procesando datos de Crucero220->Barriles220 [90/282]\n",
      "Procesando datos de Crucero220->Chacaya220 [91/282]\n",
      "Procesando datos de Crucero220->Chuquicamata220 [92/282]\n",
      "Procesando datos de Crucero220->Conchi220 [93/282]\n",
      "Procesando datos de Crucero220->ElLoa220 [94/282]\n",
      "Procesando datos de Crucero220->Laberinto220 [95/282]\n",
      "Procesando datos de Crucero220->LaCruz220 [96/282]\n",
      "Procesando datos de Crucero220->MariaElena220 [97/282]\n",
      "Procesando datos de Crucero220->Salar220 [98/282]\n",
      "Procesando datos de Crucero220->Tocopilla220 [99/282]\n",
      "Procesando datos de Cumbres500->NvaCardones500 [100/282]\n",
      "Procesando datos de DAlmagro220->DAlmagro110 [101/282]\n",
      "Procesando datos de DArica066->Arica066 [102/282]\n",
      "Procesando datos de DonaCarmen220->Nogales220 [103/282]\n",
      "Procesando datos de DonGoyo220->LaCebada220 [104/282]\n",
      "Procesando datos de DonGoyo220->Talinay220 [105/282]\n",
      "Procesando datos de DonHector220->PColorada220 [106/282]\n",
      "Procesando datos de Duqueco220->Temuco220 [107/282]\n",
      "Procesando datos de ElCobre220->Esperanza220 [108/282]\n",
      "Procesando datos de ElLoa220->Tocopilla220 [109/282]\n",
      "Procesando datos de ElSalto110->SCristobal110 [110/282]\n",
      "Procesando datos de ElTesoro220->Esperanza220 [111/282]\n",
      "Procesando datos de Encuentro220->Colla220 [112/282]\n",
      "Procesando datos de Encuentro220->ElTesoro220 [113/282]\n",
      "Procesando datos de Encuentro220->Lagunas220 [114/282]\n",
      "Procesando datos de Encuentro220->Miraje220 [115/282]\n",
      "Procesando datos de EntreRios500->Ancoa500 [116/282]\n",
      "Procesando datos de EntreRios500->Charrua500 [117/282]\n",
      "Procesando datos de EntreRios500->EntreRios220 [118/282]\n",
      "Procesando datos de Esmeralda110->Portada110 [119/282]\n",
      "Procesando datos de Esmeralda220->Esmeralda110 [120/282]\n",
      "Procesando datos de Florida110->Almendros110 [121/282]\n",
      "Procesando datos de Florida110->StaRosa110 [122/282]\n",
      "Procesando datos de Fopaco154->Lagunillas154 [123/282]\n",
      "Procesando datos de Francisco220->DAlmagro220 [124/282]\n",
      "Procesando datos de GasAta220->Esmeralda220 [125/282]\n",
      "Procesando datos de Guacolda220->Maitenc220 [126/282]\n",
      "Procesando datos de Hualpen154->Mapal154 [127/282]\n",
      "Procesando datos de Hualpen220->Hualpen154 [128/282]\n",
      "Procesando datos de Illapa220->Cumbres500 [129/282]\n",
      "Procesando datos de Illapa220->DAlmagro220 [130/282]\n",
      "Procesando datos de Itahue154->Maule154- mixed [131/282]\n",
      "Procesando datos de Itahue154->Teno154 [132/282]\n",
      "Procesando datos de Itahue220->Maule220 [133/282]\n",
      "Procesando datos de Kapatur220->Laberinto220 [134/282]\n",
      "Procesando datos de Kapatur220->Ohiggins220 [135/282]\n",
      "Procesando datos de Laberinto220->ElCobre220 [136/282]\n",
      "Procesando datos de Laberinto220->Mantos220 [137/282]\n",
      "Procesando datos de Laberinto220->NvaZald220 [138/282]\n",
      "Procesando datos de Laberinto220->Oeste220 [139/282]\n",
      "Procesando datos de LaCebada220->MRedondo220 [140/282]\n",
      "Procesando datos de LaCebada220->PuntaSierra220 [141/282]\n",
      "Procesando datos de Lagunas220->Collahuasi220 [142/282]\n",
      "Procesando datos de Lagunas220->NvaVictoria220 [143/282]\n",
      "Procesando datos de Lagunas220->Tarapaca220 [144/282]\n",
      "Procesando datos de Lagunillas154->Coronel154 [145/282]\n",
      "Procesando datos de Lagunillas220->Hualpen220 [146/282]\n",
      "Procesando datos de Lagunillas220->Lagunillas154 [147/282]\n",
      "Procesando datos de LaNegra110->AltoNorte110 [148/282]\n",
      "Procesando datos de LoAguirre220->CNavia220 [149/282]\n",
      "Procesando datos de LoAguirre500->AJahuel500 [150/282]\n",
      "Procesando datos de LoAguirre500->LoAguirre220 [151/282]\n",
      "Procesando datos de LoAguirre500->Polpaico500 [152/282]\n",
      "Procesando datos de LoEspejo110->Ochagavia110 [153/282]\n",
      "Procesando datos de LosChangos220->Kapatur220 [154/282]\n",
      "Procesando datos de LosChangos500->Cumbres500 [155/282]\n",
      "Procesando datos de LosChangos500->Kimal500_I [156/282]\n",
      "Procesando datos de LosChangos500->LosChangos220 [157/282]\n",
      "Procesando datos de LPalmas220->LVilos220 [158/282]\n",
      "Procesando datos de LVilos220->DonaCarmen220 [159/282]\n",
      "Procesando datos de LVilos220->Nogales220 [160/282]\n",
      "Procesando datos de Maitenc110->Cardones110 [161/282]\n",
      "Procesando datos de Maitenc110->Huasco110 [162/282]\n",
      "Procesando datos de Maitenc220->Cardones220 [163/282]\n",
      "Procesando datos de Maitenc220->DonHector220 [164/282]\n",
      "Procesando datos de Maitenc220->Maitenc110 [165/282]\n",
      "Procesando datos de Malloa154->Tinguiririca154 [166/282]\n",
      "Procesando datos de Mapal154->Fopaco154 [167/282]\n",
      "Procesando datos de MariaElena220->Lagunas220 [168/282]\n",
      "Procesando datos de MariaElena220->NvaVictoria220 [169/282]\n",
      "Procesando datos de Maule154->Linares154 [170/282]\n",
      "Procesando datos de Maule154->SMiguel066 [171/282]\n",
      "Procesando datos de Mejillones110->Pampa110 [172/282]\n",
      "Procesando datos de Mejillones220->Mejillones110 [173/282]\n",
      "Procesando datos de Mejillones220->OHiggins220 [174/282]\n",
      "Procesando datos de Miraje220->Atacama220 [175/282]\n",
      "Procesando datos de Miraje220->TOEnlace220 [176/282]\n",
      "Procesando datos de MRedondo220->PuntaSierra220 [177/282]\n",
      "Procesando datos de Mulchen220->Cautin220 [178/282]\n",
      "Procesando datos de Nogales220->Polpaico220 [179/282]\n",
      "Procesando datos de Nogales220->Quillota220 [180/282]\n",
      "Procesando datos de Nogales220->Ventanas220 [181/282]\n",
      "Procesando datos de Norgener220->Barriles220 [182/282]\n",
      "Procesando datos de Norgener220->LaCruz220 [183/282]\n",
      "Procesando datos de NvaCardones500->Cardones220 [184/282]\n",
      "Procesando datos de NvaMaitenc500->Maitenc220 [185/282]\n",
      "Procesando datos de NvaMaitenc500->NvaCardones500 [186/282]\n",
      "Procesando datos de NvaPAzucar500->NvaMaitenc500 [187/282]\n",
      "Procesando datos de NvaPAzucar500->PAzucar220 [188/282]\n",
      "Procesando datos de NvaPAzucar500->Polpaico500_I- mixed [189/282]\n",
      "Procesando datos de NvaPAzucar500->Polpaico500_II [190/282]\n",
      "Procesando datos de NvaZaldivar220->Andes220 [191/282]\n",
      "Procesando datos de NvaZaldivar220->Domeyko220 [192/282]\n",
      "Procesando datos de Ochagavia110->Florida110 [193/282]\n",
      "Procesando datos de OHiggins220->Domeyko220 [194/282]\n",
      "Procesando datos de OHiggins220->Palestina220 [195/282]\n",
      "Procesando datos de Pachacama110->LVegas110 [196/282]\n",
      "Procesando datos de Paine154->Tuniche154_I [197/282]\n",
      "Procesando datos de Palestina220->Domeyko220 [198/282]\n",
      "Procesando datos de PAlmonte220->Condores220 [199/282]\n",
      "Procesando datos de PAlmonte220->Lagunas220 [200/282]\n",
      "Procesando datos de PAlmonte220->PAlmonte110 [201/282]\n",
      "Procesando datos de Pampa110->Desalant110 [202/282]\n",
      "Procesando datos de Pangue220->Cholguan220 [203/282]\n",
      "Procesando datos de Pangue220->Trupan220 [204/282]\n",
      "Procesando datos de Paposo220->Cachiyuyal220 [205/282]\n",
      "Procesando datos de Paposo220->Francisco220 [206/282]\n",
      "Procesando datos de PAzucar110->ElPenon110 [207/282]\n",
      "Procesando datos de PAzucar220->DonGoyo220 [208/282]\n",
      "Procesando datos de PAzucar220->PAzucar110 [209/282]\n",
      "Procesando datos de PColorada220->PAzucar220 [210/282]\n",
      "Procesando datos de Pehuenche220->Ancoa220 [211/282]\n",
      "Procesando datos de Petroquim154->Hualpen154 [212/282]\n",
      "Procesando datos de Pid-Pid110->Chonchi110 [213/282]\n",
      "Procesando datos de Pillanlelbun066->Lautaro066 [214/282]\n",
      "Procesando datos de PMontt220->Chiloe110 [215/282]\n",
      "Procesando datos de PMontt220->Molinos110 [216/282]\n",
      "Procesando datos de PNegro220->Candela220 [217/282]\n",
      "Procesando datos de Polpaico220->ElSalto110 [218/282]\n",
      "Procesando datos de Polpaico500->Polpaico220 [219/282]\n",
      "Procesando datos de PPeuco110->LVegas110_I [220/282]\n",
      "Procesando datos de Prrahue220->Rahue220 [221/282]\n",
      "Procesando datos de Prropulli220->Prrahue220 [222/282]\n",
      "Procesando datos de Prropulli220->Rahue220 [223/282]\n",
      "Procesando datos de Prropulli220->Tineo220 [224/282]\n",
      "Procesando datos de PuntaSierra220->LPalmas220 [225/282]\n",
      "Procesando datos de Quillota110->Mirafl110 [226/282]\n",
      "Procesando datos de Quillota110->Pachacam110 [227/282]\n",
      "Procesando datos de Quillota220->Polpaico220 [228/282]\n",
      "Procesando datos de Quillota220->Quillota110 [229/282]\n",
      "Procesando datos de Quintero220->SanLuis220 [230/282]\n",
      "Procesando datos de Rahue220->Tineo220 [231/282]\n",
      "Procesando datos de Rancagua154->Tuniche154_I [232/282]\n",
      "Procesando datos de Rancagua154->Tuniche154_II [233/282]\n",
      "Procesando datos de Rapel220->AMelipill220 [234/282]\n",
      "Procesando datos de Rapel220->LoAguirre220 [235/282]\n",
      "Procesando datos de Renca110->CNavia110 [236/282]\n",
      "Procesando datos de RioTolten220->Ciruelos220 [237/282]\n",
      "Procesando datos de Rucue220->Charrua220 [238/282]\n",
      "Procesando datos de Salar110->Salar220 [239/282]\n",
      "Procesando datos de Salar220->Chuquicamata220 [240/282]\n",
      "Procesando datos de Salta345->Andes345 [241/282]\n",
      "Procesando datos de SanLuis220->ASanta220 [242/282]\n",
      "Procesando datos de SanLuis220->Quillota220 [243/282]\n",
      "Procesando datos de SantaMaria220->Charrua220 [244/282]\n",
      "Procesando datos de SantaMarta220->Chena220 [245/282]\n",
      "Procesando datos de Sauzal110_2->Sauzal154 [246/282]\n",
      "Procesando datos de Sauzal154->Rancagua154 [247/282]\n",
      "Procesando datos de SCristobal110->CNavia110 [248/282]\n",
      "Procesando datos de SFcoMost066->Paine154 [249/282]\n",
      "Procesando datos de SJavier66->Constituci66 [250/282]\n",
      "Procesando datos de S-Km6100->Salar110 [251/282]\n",
      "Procesando datos de SMiguel66->Talca66 [252/282]\n",
      "Procesando datos de StaRosa110->AJahuel110 [253/282]\n",
      "Procesando datos de SVicente154->Hualpen154 [254/282]\n",
      "Procesando datos de SVicente154->Petroq154 [255/282]\n",
      "Procesando datos de Talca66->SJavier66 [256/282]\n",
      "Procesando datos de Talinay220->LaCebada220 [257/282]\n",
      "Procesando datos de Tamaya110->S-AA100_3B [258/282]\n",
      "Procesando datos de Tamaya110->Salar110_4B [259/282]\n",
      "Procesando datos de Tarapaca220->Condores220 [260/282]\n",
      "Procesando datos de Temuco220->Cautin220 [261/282]\n",
      "Procesando datos de Temuco220->Temuco66 [262/282]\n",
      "Procesando datos de Temuco66->Pillanlelbun66 [263/282]\n",
      "Procesando datos de Tilcoco154->Malloa154 [264/282]\n",
      "Procesando datos de Tilcoco154->PCortes154 [265/282]\n",
      "Procesando datos de Tineo220->PMontt220 [266/282]\n",
      "Procesando datos de Tinguiririca154->Itahue154 [267/282]\n",
      "Procesando datos de Tinguiririca154->Teno154 [268/282]\n",
      "Procesando datos de TO_Enlace220->Atacama220 [269/282]\n",
      "Procesando datos de Tocopilla110->S-AA100 [270/282]\n",
      "Procesando datos de Tocopilla110->Tamaya110 [271/282]\n",
      "Procesando datos de Tocopilla220->Tocopi110 [272/282]\n",
      "Procesando datos de Torquemada110->Mirafl110 [273/282]\n",
      "Procesando datos de Trupan220->Charrua220 [274/282]\n",
      "Procesando datos de Tuniche_1->PCortes154 [275/282]\n",
      "Procesando datos de Tuniche_1->Tinguiririca154 [276/282]\n",
      "Procesando datos de Tuniche_2->PCortes154 [277/282]\n",
      "Procesando datos de Valdivia220->Prropulli220 [278/282]\n",
      "Procesando datos de Ventanas110->Mirafl110 [279/282]\n",
      "Procesando datos de Ventanas110->Quillota110 [280/282]\n",
      "Procesando datos de Ventanas110->Torquemada110 [281/282]\n",
      "Procesando datos de Ventanas220->Ventanas110 [282/282]\n"
     ]
    }
   ],
   "source": [
    "def percentilFL():\n",
    "    datos_lineas=plplin[['id','Hidro', 'time', 'LinName', 'LinFluP', 'capacity']]\n",
    "    lista_lineas = datos_lineas.LinName.unique()\n",
    "    n_lineas = len(lista_lineas)\n",
    "    i=1\n",
    "    for linea in lista_lineas:\n",
    "        print(f'Procesando datos de {linea} [{i}/{n_lineas}]')\n",
    "        data_lineaTx = datos_lineas.loc[(datos_lineas.LinName == linea)]\n",
    "        idlin=data_lineaTx['id'].unique()[0]\n",
    "        data_lineaTx = data_lineaTx[~(data_lineaTx['Hidro'] == 'MEDIA')]\n",
    "        fluMax = data_lineaTx[['time','capacity']]\n",
    "        xy =-fluMax.groupby(['time']).max()\n",
    "        data_lineaTx = data_lineaTx.groupby(['time']).agg(perc0=('LinFluP', lambda x: x.quantile(0.0)),\n",
    "                                                                perc20=(\n",
    "                                                                    'LinFluP', lambda x: x.quantile(0.2)),\n",
    "                                                                perc80=(\n",
    "                                                                    'LinFluP', lambda x: x.quantile(0.8)),\n",
    "                                                                perc100=('LinFluP', lambda x: x.quantile(1)))\n",
    "\n",
    "        data_lineaTx['Min'] = xy\n",
    "        data_lineaTx['Max'] = -xy\n",
    "        i = i+1\n",
    "        data_lineaTx.reset_index(inplace=True)\n",
    "        data_lineaTx = data_lineaTx.assign(id=idlin)\n",
    "        data_lineaTx = data_lineaTx.assign(LinName = linea)\n",
    "        data_lineaTx.to_json(line_flow_percentil_path+f\"/line_{idlin}.json\",orient='records')\n",
    "\n",
    "percentilFL()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenarios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando scenarios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% Completado\n"
     ]
    }
   ],
   "source": [
    "# Bus contiene:\n",
    "'''\n",
    "\t\t(*) id <int>: identificador de la barra \n",
    "\t\t(*) time <int>: instante de registro\n",
    "\t\t(*) name <str>: nombre de la barra\n",
    "\t\tmarginal_cost <float>: costo marginal, genera el gráfico de costo\n",
    "\t\t\t\t\t[USD/MWh]\n",
    "\t\tDemBarE <float>: construye el gráfico de demanda de Energía [MWh]\n",
    "\t\tDemBarP <float>: construye el gráfico de demanda de Potencia [MW]\n",
    "\t\tValue <float>: mismo valor que marginal_cost [MWh]\n",
    "'''\n",
    "\n",
    "def busscenariofunction(dfbusauxlist, pathbus):\n",
    "    for x in range(nbus): \n",
    "        idbus = indexbus['id'][x]\n",
    "        aux = pd.DataFrame({\n",
    "            'id': idbus,\n",
    "            'time': dfbusauxlist[x]['time'],\n",
    "            'name': indexbus['BarName'][x],\n",
    "            'marginal_cost': dfbusauxlist[x]['CMgBar'],\n",
    "            'value': dfbusauxlist[x]['CMgBar'],\n",
    "            'DemBarE': dfbusauxlist[x]['DemBarE'],\n",
    "            'DemBarP': dfbusauxlist[x]['DemBarP'],\n",
    "            'BarRetP': dfbusauxlist[x]['BarRetP']\n",
    "        })\n",
    "        aux.to_json(pathbus + f\"/bus_{idbus}.json\", orient='records')\n",
    "\n",
    "\n",
    "for hidronum,hidroname in enumerate(hidrolist):\n",
    "\t\n",
    "\tdfbussauxx=plpbar.query(f\"(Hidro=='{hidroname}')\").reset_index()\n",
    "\tdfbuslist=[]\n",
    "\tfor idaux in lbus:\n",
    "\t\tdfbuslist.append(dfbussauxx[dfbussauxx.id==idaux].reset_index(drop=True))\n",
    "\tprint(f\"{((hidronum+1)/len(hidrolist))*100}% Completado\")\n",
    "\tbusscenariofunction(dfbuslist,busscenariolist[hidronum])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% Completado\n"
     ]
    }
   ],
   "source": [
    "# Centrals contiene:\n",
    "'''\n",
    "\t\t(*) id <int>: identificador del generador\n",
    "\t\t(*) time <int>: instante de registro\n",
    "\t\t(*) bus_id <int>: identificador de la barra a la que se conecta\n",
    "\t\t(*) name <str>: nombre del generador\n",
    "\t\tCenPgen <float>: energía generada en el instante time [MW]\n",
    "\t\tvalue <float>: mismo valor que CenPgen [MW]\n",
    "\t\t(?) CenCVar <unknown>: parámetro no identificado\n",
    "\t\t(?) CenQgen <unknown>: parámetro no identificado\n",
    "        \n",
    "'''\n",
    "\n",
    "def centralscenariofunction(dfcenauxlist, cenpath):\n",
    "    for x in range(ngen):\n",
    "        if indexcen['bus_id'][x] == 0 or np.isnan(indexcen['bus_id'][x]):\n",
    "            continue\n",
    "        aux_df = pd.DataFrame({\n",
    "            'id': indexcen['id'][x],\n",
    "            'time': range(1, time + 1),\n",
    "            'bus_id': int(indexcen['bus_id'][x]),\n",
    "            'name': indexcen['CenName'][x],\n",
    "            'CenPgen': dfcenauxlist[x]['CenPgen'] if len(dfcenauxlist[x]) > 0 else [0]*time,\n",
    "            'value': dfcenauxlist[x]['CenPgen'] if len(dfcenauxlist[x]) > 0 else [0]*time,\n",
    "            'CenCVar': dfcenauxlist[x]['CenCVar'] if len(dfcenauxlist[x]) > 0 else [0]*time,\n",
    "            'CenQgen': dfcenauxlist[x]['CenQgen'] if len(dfcenauxlist[x]) > 0 else [0]*time,\n",
    "        })\n",
    "        aux_df.to_json(cenpath + f\"/central_{indexcen['id'][x]}.json\", orient='records')\n",
    "\n",
    "for hidronum, hidroname in enumerate(hidrolist):\n",
    "    dfcensauxx = plpcen.query(f\"(Hidro=='{hidroname}')\").reset_index()\n",
    "    dfcenlist = [dfcensauxx[dfcensauxx.id == indexcen['id'][x]].reset_index(drop=True) for x in range(ngen)]\n",
    "    print(f\"{((hidronum + 1) / len(hidrolist)) * 100}% Completado\")\n",
    "    centralscenariofunction(dfcenlist, centralscenariolist[hidronum])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% Completado\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "        (*) id <int>: identificador de la linea \n",
    "\t\t(*) time <int>: instante de registro\n",
    "\t\t(*) bus_a <int>: identificador de la barra de origen\n",
    "\t\t(*) bus_b <int>: identificador de la barra de destino\n",
    "\t\tflow <float>: flujo en el instante time [MW]\n",
    "\t\tvalue <float>: mismo valor que flow [MW]    \n",
    "'''\n",
    "def linescenariofunction(dflinelist, linpath):\n",
    "    for x in range(nlin):\n",
    "        if linesfinal['active'][x] != 1:\n",
    "            continue\n",
    "        idaux = linesfinal['id'][x]\n",
    "        bus_a_id = linesfinal['bus_a'][x]\n",
    "        bus_b_id = linesfinal['bus_b'][x]\n",
    "        name = linesfinal['LinName'][x]\n",
    "        aux_df = pd.DataFrame({\n",
    "            'id': idaux,\n",
    "            'time': range(1, time + 1),\n",
    "            'name': name,\n",
    "            'bus_a': bus_a_id,\n",
    "            'bus_b': bus_b_id,\n",
    "            'flow': dflinelist[x]['LinFluP'],\n",
    "            'value': dflinelist[x]['LinFluP'],\n",
    "            'capacity': dflinelist[x]['capacity'],\n",
    "        })\n",
    "        aux_df.to_json(linpath + f\"/line_{idaux}.json\", orient='records')\n",
    "\n",
    "for hidronum, hidroname in enumerate(hidrolist):\n",
    "    dflinesaux = plplin.query(f\"(Hidro=='{hidroname}')\").reset_index()\n",
    "    dflinelist = [dflinesaux[dflinesaux.id == linesfinal['id'][x]].reset_index(drop=True) for x in range(nlin)]\n",
    "    print(f\"{((hidronum + 1) / len(hidrolist)) * 100}% Completado\")\n",
    "    linescenariofunction(dflinelist, linescenariolist[hidronum])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\t\\t(*) time <int>: instante de registro\\n\\t\\t(*) id <int>: identificador del embalse\\n\\t\\t(*) junction_id <int>: identificador del canal al que se conecta\\n\\t\\t(*) name <str>: nombre del embalse\\n\\t\\tlevel <float>: nivel en el instante time\\n\\t\\tvalue <float>: mismo valor que level\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resevoirs contiene:\n",
    "'''\n",
    "\t\t(*) time <int>: instante de registro\n",
    "\t\t(*) id <int>: identificador del embalse\n",
    "\t\t(*) junction_id <int>: identificador del canal al que se conecta\n",
    "\t\t(*) name <str>: nombre del embalse\n",
    "\t\tlevel <float>: nivel en el instante time\n",
    "\t\tvalue <float>: mismo valor que level\n",
    "'''\n",
    "\n",
    "\n",
    "# def resscenariofunction(dfreslist, respath):\n",
    "#     for x in range(nres):\n",
    "#         idaux = indexres['id'][x]\n",
    "#         name = indexres['EmbName'][x]\n",
    "#         junction_id = junctionsinfo[junctionsinfo['CenName'] == name]['id'].values[0]\n",
    "#         aux_df = pd.DataFrame({\n",
    "#             'time': range(1, time + 1),\n",
    "#             'id': idaux,\n",
    "#             'junction_id': junction_id,\n",
    "#             'name': name,\n",
    "#             'level': (dfreslist[x]['EmbFac'] * dfreslist[x]['EmbVfin']) / 1000000,\n",
    "#             'value': (dfreslist[x]['EmbFac'] * dfreslist[x]['EmbVfin']) / 1000000,\n",
    "#         })\n",
    "#         aux_df.to_json(respath + f\"/reservoir_{idaux}.json\", orient='records')\n",
    "\n",
    "# for hidronum, hidroname in enumerate(hidrolist):\n",
    "#     dfresaux = reservoirs.query(f\"(Hidro=='{hidroname}')\").reset_index()\n",
    "#     dfreslist = [dfresaux[dfresaux.id == indexres['id'][x]].reset_index(drop=True) for x in range(nres)]\n",
    "#     print(f\"{((hidronum + 1) / len(hidrolist)) * 100}% Completado\")\n",
    "#     resscenariofunction(dfreslist, reservoirscenariolist[hidronum])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topology"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubibar[['latUTM','lonUTM']]=ubibar.apply(lambda row: valorXY(row['latitud'],row['longitud'],scale=0.001),axis=1,result_type='expand')\n",
    "dirdfbus=ubibar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bus electric contiene:\n",
    "\n",
    "'''   \n",
    "\t\t(*) id <int>: identificador de la barra\n",
    "\t\t(*) name <str>: nombre de la barra\n",
    "\t\tlongitude <float>\n",
    "\t\tlatitude <float>\n",
    "\t\tactive <int>: indica si la barra está activa\n",
    "'''\n",
    "auxiliar=[]\n",
    "buselectricfilas_aux=[]\n",
    "for x in range(nbus): # Para cada barra (bus)\n",
    "\tif dirdfbus['BarName'].isin([indexbus['BarName'][x]]).tolist().count(True)>0:\n",
    "\t\tlatitud=float(dirdfbus[dirdfbus['BarName']==indexbus['BarName'][x]]['latitud'].values[0])\n",
    "\t\tlongitud=float(dirdfbus[dirdfbus['BarName']==indexbus['BarName'][x]]['longitud'].values[0])\n",
    "\telse:\n",
    "\t\tauxiliar.append(indexbus['BarName'][x])\n",
    "\t\tlatitud,longitud=aleatory_direction()\n",
    "\n",
    "\taux=[]\n",
    "\taux.append(indexbus['id'][x])\n",
    "\taux.append(indexbus['BarName'][x])\n",
    "\taux.append(longitud)\n",
    "\taux.append(latitud)\n",
    "\taux.append(1)\n",
    "\tbuselectricfilas_aux.append(aux)\n",
    "\n",
    "buselectric=pd.DataFrame(buselectricfilas_aux,columns=['id','name','longitude','latitude','active'])\n",
    "\n",
    "buselectric.to_json(electricTopology+\"/bus.json\",orient='records')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### centrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centrals electric contiene:\n",
    "\n",
    "'''   \n",
    "        (*) id <int>: identificador del generador\n",
    "\t\t(*) bus_id <int>: id de la barra conectada al generador\n",
    "\t\t(*) name <str>: nombre del generador\n",
    "\t\tactive <int>: indica si el generador está activo\n",
    "\t\tcapacity <float>: capacidad del generador [MW]\n",
    "\t\tmin_power <float>: generación mínima [MW]\n",
    "\t\tmax_power <float>: generación máxima [MW]\n",
    "\t\ttype <str>: tipo de generador\n",
    "\t\tlongitude <float>\n",
    "\t\tlatitude <float>\n",
    "\t\t(?) effinciency <float>: Rendimiento [MWh/m3s]\n",
    "\t\t(?) flow <float>: parámetro no identificado\n",
    "\t\t(?) rmin <float>: parámetro no identificado\n",
    "\t\t(?) rmax <float>: parámetro no identificado\n",
    "\t\t(?) cvar <float>: Costo Variable\n",
    "\t\t(?) cvnc <unknown>: parámetro no identificado\n",
    "\t\t(?) cvc <unknown>: parámetro no identificado\n",
    "\t\t(?) entry_date <unknown>: parámetro no identificado\n",
    "\n",
    "'''\n",
    "\n",
    "centralselectricfilas_aux=[]\n",
    "for x in range(ngen): # Para cada generador (central)\n",
    "\tif indexcen['bus_id'][x]==0 or np.isnan(indexcen['bus_id'][x]): # No existe la barra 0, por lo que no se consideran dichos generadores\n",
    "\t\tpass\n",
    "\telse:\n",
    "\t\tlatitud,longitud=None,None\n",
    "\t\taux=[]\n",
    "\t\taux.append(indexcen['id'][x])\n",
    "\t\taux.append(int(indexcen['bus_id'][x]))\n",
    "\t\taux.append(indexcen['CenName'][x])\n",
    "\t\taux.append(1)\n",
    "\t\t# capacidad\n",
    "\t\taux.append(0)\n",
    "\t\taux.append(centralsinfo[centralsinfo['CenName']==indexcen['CenName'][x]]['min_power'])\n",
    "\t\taux.append(centralsinfo[centralsinfo['CenName']==indexcen['CenName'][x]]['max_power'])\n",
    "\t\ttipo=typecentrals[typecentrals['CenName']==indexcen['CenName'][x]]['cen_type'].values\n",
    "\t\tif len(tipo)>0:\n",
    "\t\t\taux.append(tipo[0])\n",
    "\t\telse:\n",
    "\t\t\taux.append(\"otros\")\n",
    "\t\taux.append(longitud)\n",
    "\t\taux.append(latitud)\n",
    "\t\taux.append(centralsinfo[centralsinfo['CenName']==indexcen['CenName'][x]]['effinciency'])\n",
    "\t\tfor x in range(7):\n",
    "\t\t\taux.append(0)\n",
    "\t\tcentralselectricfilas_aux.append(aux)\n",
    "\n",
    "centralelectric=pd.DataFrame(centralselectricfilas_aux,columns=['id','bus_id','name','active','capacity','min_power','max_power','type','longitude','latitude','efficiency','flow','rmin','rmax','cvar',\n",
    "'cvnc','cvc','entry_date'])\n",
    "\n",
    "centralelectric.to_json(electricTopology+\"/centrals.json\",orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines electric tiene:\n",
    "'''  \n",
    "        (*) id <int>: identificador de la línea\n",
    "\t\t(*) bus_a <int>: id de la barra origen\n",
    "\t\t(*) bus_b <int>: id de la barra destino\n",
    "\t\tactive <int>: indica si la línea está activa\n",
    "\t\tcapacity <float>: capacidad máxima de la línea [MW]  ->\n",
    "\t\tmax_flow_a_b <float>: flujo máximo en dirección\n",
    "\t\t\t\t\tdispuesta [MW]\n",
    "\t\tmax_flow_b_a <float>: flujo máximo en dirección\n",
    "\t\t\t\t\tcontraria [MW]\n",
    "\t\tvoltage <float>: voltaje de la línea [kV]\n",
    "\t\tr <float>: resistencia de la línea [Ω]\n",
    "\t\tx <float>: reactancia de la línea [Ω]\n",
    "\t\t(? )segments <int>: parámetro no identificado\n",
    "\t\t(?) entry_date <unknown>: parámetro no identificado\n",
    "\t\t(?) exit_date <unknown>: parámetro no identificado\n",
    "\n",
    "'''\n",
    "\n",
    "lineselectricfilas_aux=[]\n",
    "for x in range(nlin): # Para cada linea\n",
    "\tif linesfinal['active'][x]==1:\n",
    "\t\taux=[]\n",
    "\t\tbus_a_id = linesfinal['bus_a'][x]\n",
    "\t\tbus_b_id = linesfinal['bus_b'][x]\n",
    "\t\tname = linesfinal['LinName'][x]\n",
    "\t\taux.append(linesfinal['id'][x])\n",
    "\t\taux.append(name)\n",
    "\t\taux.append(bus_a_id)\n",
    "\t\taux.append(bus_b_id)\n",
    "\t\taux.append(1)\n",
    "\t\t# capacidad\n",
    "\t\taux.append(0)\n",
    "\t\taux.append(linesfinal['max_flow_a_b'][x])\n",
    "\t\taux.append(linesfinal['max_flow_b_a'][x])\n",
    "\t\taux.append(linesfinal['voltage'][x])\n",
    "\t\taux.append(linesfinal['r'][x])\n",
    "\t\taux.append(linesfinal['x'][x])\n",
    "\t\taux.append(linesfinal['segments'][x])\n",
    "\t\taux.append(None)\n",
    "\t\taux.append(None)\n",
    "\t\tlineselectricfilas_aux.append(aux)\n",
    "\n",
    "lineelectric=pd.DataFrame(lineselectricfilas_aux,columns=['id','name','bus_a','bus_b','active','capacity','max_flow_a_b','max_flow_b_a','voltage','r','x','segments','entry_date','exit_date'])\n",
    "\n",
    "lineelectric.to_json(electricTopology+\"/lines.json\",orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   \\n        (*) id <int>: identificador del embalse\\n\\t\\t(*) junction_id <int>: id del embalse relacionada (mismo valor id)\\n\\t\\t(*) name <str>: nombre del embalse\\n\\t\\t(*) type <str>: tipo de embalse\\n\\t\\tmin_vol <float>: volumen mínimo del embalse\\n\\t\\tmax_vol <float>: volumen máximo del embalse\\n\\t\\tstart_vol <float>: volumen inicial del embalse\\n\\t\\tend_vol <float>: volumen final del embalse\\n\\t\\tactive <bool>: indica si el embalse está activo\\n\\t\\t(?) hyd_independant <bool>: parámetro no identificado\\n\\t\\t(?) future_cost <unknown>: parámetro no identificado\\n\\t\\t(?) cmin <unknown>: cota m.s.n.m mínima\\n\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''   \n",
    "        (*) id <int>: identificador del embalse\n",
    "\t\t(*) junction_id <int>: id del embalse relacionada (mismo valor id)\n",
    "\t\t(*) name <str>: nombre del embalse\n",
    "\t\t(*) type <str>: tipo de embalse\n",
    "\t\tmin_vol <float>: volumen mínimo del embalse\n",
    "\t\tmax_vol <float>: volumen máximo del embalse\n",
    "\t\tstart_vol <float>: volumen inicial del embalse\n",
    "\t\tend_vol <float>: volumen final del embalse\n",
    "\t\tactive <bool>: indica si el embalse está activo\n",
    "\t\t(?) hyd_independant <bool>: parámetro no identificado\n",
    "\t\t(?) future_cost <unknown>: parámetro no identificado\n",
    "\t\t(?) cmin <unknown>: cota m.s.n.m mínima\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# reshydricfilas_aux=[]\n",
    "# for x in range(nres): # Para cada linea\n",
    "# \taux=[]\n",
    "# \tidaux=indexres['id'][x]\n",
    "# \tname=indexres['EmbName'][x]\n",
    "# \tjunction_id = junctionsinfo[junctionsinfo['CenName']==name]['id'].values[0]\n",
    "\t\n",
    "# \taux.append(idaux)\n",
    "# \taux.append(junction_id)\n",
    "# \taux.append(name)\n",
    "# \taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['type'].values[0])\n",
    "# \taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['VembMin'].values[0])\n",
    "# \taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['VembMax'].values[0])\n",
    "# \taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['VembIn'].values[0])\n",
    "# \taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['VembFin'].values[0])\n",
    "# \taux.append(1)\n",
    "# \taux.append(0)\n",
    "# \taux.append(None)\n",
    "# \taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['cotaMínima'].values[0])\n",
    "# \treshydricfilas_aux.append(aux)\n",
    "\n",
    "# reshydric=pd.DataFrame(reshydricfilas_aux,columns=['id','junction_id','name','type','min_vol','max_vol','start_vol','end_vol','active','hyd_independant','future_cost','cmin'])\n",
    "\n",
    "# reshydric.to_json(hydricTopology+\"/reservoirs.json\",orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Junctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\t(*) id <int>: identificador de la unión\\n\\t(*) name <str>: nombre de la unión\\n\\tlongitude <float>\\n\\tlatitude <float>\\n\\tactive <bool>: indica si la barra está activa\\n\\tdrainage <bool>: parámetro no identificado\\n\\tbus_id\\n\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\t(*) id <int>: identificador de la unión\n",
    "\t(*) name <str>: nombre de la unión\n",
    "\tlongitude <float>\n",
    "\tlatitude <float>\n",
    "\tactive <bool>: indica si la barra está activa\n",
    "\tdrainage <bool>: parámetro no identificado\n",
    "\tbus_id\n",
    "\n",
    "'''\n",
    "\n",
    "# junctionhydricfilas_aux=[]\n",
    "# for x in range(len(junctionsinfo)): # Para cada junction\n",
    "# \tlatitud,longitud=aleatory_direction()\n",
    "# \taux=[]\n",
    "# \taux.append(junctionsinfo['id'][x])\n",
    "# \taux.append(junctionsinfo['CenName'][x])\n",
    "# \taux.append(longitud)\n",
    "# \taux.append(latitud)\n",
    "# \taux.append(1)\n",
    "# \taux.append(0)\n",
    "# \taux.append(junctionsinfo['bus_id'][x])\n",
    "\t\n",
    "# \tjunctionhydricfilas_aux.append(aux)\n",
    "\n",
    "# junctionhydric=pd.DataFrame(junctionhydricfilas_aux,columns=['id','name','logitude','latitude','active','drainage','bus_id'])\n",
    "\n",
    "# junctionhydric.to_json(hydricTopology+\"/junctions.json\",orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waterways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        (*) id <int>: identificador del canal\\n\\t\\t(*) name <str>: nombre del canal\\n\\t\\t(*) type <str>: tipo de waterway\\n\\t\\t(*) junc_a_id <int>: id de la unión de origen\\n\\t\\t(*) junc_b_id <int>: id de la unión de destino\\n\\t\\tactive <bool>: indica si el canal está activo\\n\\t\\t(?) fmin <unknown>: parámetro no identificado\\n\\t\\t(?) fmax <unknown>: parámetro no identificado\\n\\t\\t(?) cvar <unknown>: parámetro no identificado \\n        (?) delay <unknown>: parámetro no identificado\\n\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "        (*) id <int>: identificador del canal\n",
    "\t\t(*) name <str>: nombre del canal\n",
    "\t\t(*) type <str>: tipo de waterway\n",
    "\t\t(*) junc_a_id <int>: id de la unión de origen\n",
    "\t\t(*) junc_b_id <int>: id de la unión de destino\n",
    "\t\tactive <bool>: indica si el canal está activo\n",
    "\t\t(?) fmin <unknown>: parámetro no identificado\n",
    "\t\t(?) fmax <unknown>: parámetro no identificado\n",
    "\t\t(?) cvar <unknown>: parámetro no identificado \n",
    "        (?) delay <unknown>: parámetro no identificado\n",
    "\n",
    "'''\n",
    "\n",
    "# junctionhydricfilas_aux=[]\n",
    "# countid=1\n",
    "# for x in range(len(junctionsinfo)):\n",
    "#     gen_id=junctionsinfo.serie_hidro_gen[x]\n",
    "#     ver_id=junctionsinfo.serie_hidro_ver[x]\n",
    "#     name_a = junctionsinfo.CenName[x]\n",
    "#     df_adicional = hydric_adicional[hydric_adicional['embalse'] == name_a]\n",
    "#     if not pd.isnull(gen_id):\n",
    "#         aux=[]\n",
    "#         aux.append(countid)\n",
    "#         countid+=1\n",
    "#         name_b = junctionsinfo[junctionsinfo['id']==gen_id].CenName.values[0]\n",
    "#         name = name_a+'_Gen_'+name_b\n",
    "#         aux.append(name)\n",
    "#         aux.append(\"generation\")\n",
    "#         aux.append(junctionsinfo.id[x])\n",
    "#         aux.append(gen_id)\n",
    "#         aux.append(1)\n",
    "#         aux.append(None)\n",
    "#         aux.append(None)\n",
    "#         aux.append(None)\n",
    "#         aux.append(None)\n",
    "#         junctionhydricfilas_aux.append(aux)\n",
    "\n",
    "#     if not pd.isnull(ver_id):\n",
    "#         aux=[]\n",
    "#         aux.append(countid)\n",
    "#         countid+=1\n",
    "#         name_b = junctionsinfo[junctionsinfo['id']==ver_id].CenName.values[0]\n",
    "#         name = name_a+'_Vert_'+name_b\n",
    "#         aux.append(name)\n",
    "#         aux.append(\"spillover\")\n",
    "#         aux.append(junctionsinfo.id[x])\n",
    "#         aux.append(ver_id)\n",
    "#         aux.append(1)\n",
    "#         aux.append(None)\n",
    "#         aux.append(None)\n",
    "#         aux.append(None)\n",
    "#         aux.append(None)\n",
    "#         junctionhydricfilas_aux.append(aux)\n",
    "#     if len(df_adicional)>0:\n",
    "#         for i in range(len(df_adicional)):\n",
    "#             tipo =df_adicional['type'].iloc[i]\n",
    "#             name =\"\"\n",
    "#             central = df_adicional['central'].iloc[i].lower()\n",
    "#             id_central = centralsinfo[centralsinfo['CenName'].str.lower() == central]['id'].values[0]\n",
    "#             aux=[]\n",
    "#             aux.append(countid)\n",
    "#             countid+=1\n",
    "#             name_b = junctionsinfo[junctionsinfo['id']==id_central].CenName.values[0]\n",
    "#             if tipo == \"filtration\":\n",
    "#                 name = name_a+'_Fil_'+name_b\n",
    "#             elif tipo == \"extraction\":\n",
    "#                 name = name_a+'_Ext_'+name_b\n",
    "#             aux.append(name)\n",
    "#             aux.append(tipo)\n",
    "#             aux.append(junctionsinfo.id[x])\n",
    "#             aux.append(id_central)\n",
    "#             aux.append(1)\n",
    "#             aux.append(None)\n",
    "#             aux.append(None)\n",
    "#             aux.append(None)\n",
    "#             aux.append(None)\n",
    "#             junctionhydricfilas_aux.append(aux)\n",
    "# waterwayshydric=pd.DataFrame(junctionhydricfilas_aux,columns=[\"id\",\"name\",\"type\",\"junc_a_id\",\"junc_b_id\",\"active\",\"fmin\",\"fmax\",\"cvar\",\"delay\"])\n",
    "# waterwayshydric.to_json(hydricTopology+\"/waterways.json\",orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centroenergia",
   "language": "python",
   "name": "centroenergia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
