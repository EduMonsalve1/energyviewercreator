{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import random\n",
    "import pyproj\n",
    "import shutil\n",
    "import gzip\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nombres y Direcciones particulares de cada caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirección donde se ubican los archivos que se cargarán\n",
    "path_case='C:/Users/Lenovo/Documents/Work/Practica_II/Plexos/'\n",
    "\n",
    "# Nombre que tendrá el caso\n",
    "name_Case='PLEXOS'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "remotedesk=False\n",
    "\n",
    "if remotedesk:\n",
    "    path_data='C:/Users/Centro/Documents/DataPLP/'\n",
    "else:\n",
    "    path_data=path_case"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barra import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plpbar=pd.read_csv(path_data+'plpbar.csv')\n",
    "plpbar.columns=[\"Hidro\",\"time\",\"TipoEtapa\",\"id\",\"BarName\",\"CMgBar\",\"DemBarP\",\"DemBarE\",\"PerBarP\",\"PerBarE\",\"BarRetP\",\"BarRetE\"]\n",
    "plpbar['BarName']=plpbar['BarName'].str.replace(\" \",\"\")\n",
    "plpbar[\"Hidro\"] = plpbar[\"Hidro\"].str.replace(\" \", \"\")\n",
    "\n",
    "indexbus=plpbar[['id','BarName']].drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "ubibar=pd.read_csv(path_data+'ubibar.csv',sep=';')\n",
    "ubibar=ubibar.drop('ID',axis=1)\n",
    "ubibar['LATITUD']=ubibar['LATITUD'].apply(lambda x:x.replace(',','.')).apply(float)\n",
    "ubibar['LONGITUD']=ubibar['LONGITUD'].apply(lambda x:x.replace(',','.')).apply(float)\n",
    "ubibar.columns=[\"BarName\",\"latitud\",\"longitud\"]\n",
    "ubibar['BarName']=ubibar['BarName'].str.replace(\" \",\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plpcen=pd.read_csv(path_data+'plpcen.csv')\n",
    "plpcen.columns=[\"Hidro\",\"time\",\"TipoEtapa\",\"id\",\"CenName\",\"tipo\",\"bus_id\",\"BarName\",\"CenQgen\",\"CenPgen\",\"CenEgen\",\"CenInyP\",\"CenInyE\",\"CenRen\",\"CenCVar\",\"CenCostOp\",\"CenPMax\"]\n",
    "plpcen['CenName']=plpcen[\"CenName\"].str.replace(\" \",\"\")\n",
    "plpcen=plpcen.drop([\"CenEgen\",\"CenInyP\",\"CenInyE\",\"CenRen\",\"CenCostOp\",\"CenPMax\"],axis=1)\n",
    "plpcen[\"Hidro\"] = plpcen[\"Hidro\"].str.replace(\" \", \"\")\n",
    "plpcen['tipo']=\"otros\"\n",
    "\n",
    "indexcen=plpcen[['id','CenName','tipo','bus_id']].drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "centralsinfo=pd.read_csv(path_data+'centralesinfo.csv',sep=';')\n",
    "centralsinfo.columns=['id','CenName','type','CVar','effinciency','bus_id','serie_hidro_gen','serie_hidro_ver','min_power','max_power',\"VembIn\",\"VembFin\",\"VembMin\",\"VembMax\",\"cotaMínima\"]\n",
    "\n",
    "cols = ['min_power', 'max_power', 'effinciency', 'CVar', 'VembIn', 'VembFin', 'VembMin', 'VembMax', 'cotaMínima']\n",
    "centralsinfo['CenName'] = centralsinfo[\"CenName\"].str.replace(\" \", \"\")\n",
    "for col in cols:\n",
    "    centralsinfo[col] = centralsinfo[col].replace(\",\", \".\", regex=True)\n",
    "\n",
    "#hydric_adicional = pd.read_csv(path_data+'hydric_adicional.csv',sep=\";\")\n",
    "\n",
    "tiposcentrales=pd.read_csv(path_data+'centralestype.csv', encoding=\"latin-1\").rename(columns={'cen_name':'CenName'})\n",
    "typecentrals=indexcen.merge(tiposcentrales,on='CenName')\n",
    "\n",
    "for x in range(len(indexcen['id'])):\n",
    "    tipo=typecentrals[typecentrals['CenName']==indexcen['CenName'][x]]['cen_type'].values\n",
    "    \n",
    "    if len(tipo)>0:\n",
    "        plpcen.loc[plpcen['id'] == indexcen['id'][x], 'tipo'] = tipo[0]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineas import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plplin=pd.read_csv(path_data+'plplin.csv')\n",
    "# Cambiando los nombres de las columnas\n",
    "plplin.columns=[\"Hidro\",\"time\",\"TipoEtapa\",\"id\",\"LinName\",\"bus_a\",\"bus_b\",\"LinFluP\",\"LinFluE\",\"capacity\",\"LinUso\",\"LinPerP\",\"LinPerE\",\"LinPer2P\",\"LinPer2E\",\"LinITP\",\"LinITE\"]\n",
    "plplin['LinName']=plplin['LinName'].str.replace(\" \",\"\")\n",
    "plplin[\"Hidro\"] = plplin[\"Hidro\"].str.replace(\" \", \"\")\n",
    "\n",
    "indexlin=plplin[['id','LinName',\"bus_a\",\"bus_b\"]].drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "linesinfo=pd.read_csv(path_data+'linesinfo.csv',sep=';')\n",
    "linesinfo.columns=[\"id\",\"LinName\",\"bus_a\",\"bus_b\",\"max_flow_a_b\",\"max_flow_b_a\",\"voltage\",\"r\",\"x\",\"segments\",\"active\"]\n",
    "linesinfo['LinName']=linesinfo['LinName'].str.replace(\" \",\"\")\n",
    "linesinfo['max_flow_a_b']=(linesinfo[\"max_flow_a_b\"].apply(str)).apply(lambda x:x.replace(',','.')).apply(float)\n",
    "linesinfo['max_flow_b_a']=(linesinfo['max_flow_b_a'].apply(str)).apply(lambda x:x.replace(',','.')).apply(float)\n",
    "linesinfo['r']=(linesinfo['r'].apply(str)).apply(lambda x:x.replace(',','.')).apply(float)\n",
    "linesinfo['x']=(linesinfo['x'].apply(str)).apply(lambda x:x.replace(',','.')).apply(float)\n",
    "\n",
    "linesfinal=indexlin.drop(['id','bus_a','bus_b'],axis=1).merge(linesinfo,on='LinName')\n",
    "linesfinal['id']=(linesfinal['id']).apply(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reservoirs Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reservoirs = pd.read_csv(path_data+'plpemb.csv')\n",
    "#reservoirs.rename(columns={'Bloque': 'time', 'EmbNum': 'id', 'EmbNom': 'EmbName'}, inplace=True)\n",
    "#reservoirs['EmbName']=reservoirs['EmbName'].str.replace(\" \",\"\")\n",
    "#reservoirs['Hidro']=reservoirs['Hidro'].str.replace(\" \",\"\")\n",
    "\n",
    "#indexres = reservoirs[['id','EmbName']].drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "junctionsinfo=centralsinfo[centralsinfo['type'].isin([\"E\",'S','R'])].reset_index(drop=True)\n",
    "junctionsinfo=centralsinfo[centralsinfo['type'].isin([\"E\",'S','R'])].reset_index(drop=True)\n",
    "junctionsinfo['serie_hidro_gen']=(junctionsinfo['serie_hidro_gen'].apply(str)).apply(lambda x:x.replace(',','.')).apply(float)\n",
    "junctionsinfo['serie_hidro_ver']=(junctionsinfo['serie_hidro_ver'].apply(str)).apply(lambda x:x.replace(',','.')).apply(float)\n",
    "\n",
    "reservoirsinfo=centralsinfo[centralsinfo['type'].isin([\"E\"])].reset_index(drop=True)\n",
    "reservoirsinfo.rename(columns={'CenName':'EmbName'}, inplace=True)\n",
    "\n",
    "#for i, emb_name in enumerate(reservoirsinfo['EmbName']):\n",
    "#    if emb_name in indexres['EmbName'].values:\n",
    "#        idx = indexres.index[indexres['EmbName'] == emb_name][0]\n",
    "#        reservoirsinfo.at[i, 'id'] = indexres.at[idx, 'id']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indhor import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "indhor = pd.read_csv(path_data+'indhor.csv',encoding='latin-1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando directorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre data\n",
    "namedata=name_Case\n",
    "electricTopology=namedata+'/Topology/Electric'\n",
    "hydricTopology=namedata+'/Topology/Hydric'\n",
    "\n",
    "os.makedirs(electricTopology,exist_ok=True)\n",
    "os.makedirs(hydricTopology,exist_ok=True)\n",
    "\n",
    "\n",
    "hidrolist=plpbar['Hidro'].unique()\n",
    "busscenariolist=[]\n",
    "centralscenariolist=[]\n",
    "linescenariolist=[]\n",
    "reservoirscenariolist=[]\n",
    "for hidronum in range(len(hidrolist)):\n",
    "\t# Creamos los directorios\n",
    "\tbusscenario= namedata+f'/Scenarios/{hidronum+1}/Bus'\n",
    "\tcentralscenario=namedata+f'/Scenarios/{hidronum+1}/Centrals'\n",
    "\tlinescenario=namedata+f'/Scenarios/{hidronum+1}/Lines'\n",
    "\treservoirscenario=namedata+f'/Scenarios/{hidronum+1}/Reservoirs'\n",
    "\n",
    "\tos.makedirs(busscenario,exist_ok=True)\n",
    "\tbusscenariolist.append(busscenario)\n",
    "\n",
    "\tos.makedirs(centralscenario,exist_ok=True)\n",
    "\tcentralscenariolist.append(centralscenario)\n",
    "\n",
    "\tos.makedirs(linescenario,exist_ok=True)\n",
    "\tlinescenariolist.append(linescenario)\n",
    "\n",
    "\tos.makedirs(reservoirscenario,exist_ok=True)\n",
    "\treservoirscenariolist.append(reservoirscenario)\n",
    "\n",
    "marginal_cost_path=namedata+f'/Scenarios/Marginal_cost_percentil'\n",
    "line_flow_percentil_path=namedata+f'/Scenarios/Flow_Line_percentil'\n",
    "generation_sistem_path=namedata+f'/Scenarios/Generation_system'\n",
    "os.makedirs(marginal_cost_path,exist_ok=True)\n",
    "os.makedirs(line_flow_percentil_path,exist_ok=True)\n",
    "os.makedirs(generation_sistem_path,exist_ok=True)\n",
    "hydrofile = [x for x in range(1,len(hidrolist)+1)]\n",
    "\n",
    "with open( namedata+'/Scenarios/hydrologies.json', 'w') as f:\n",
    "  json.dump(hydrofile, f)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables indicadoras de cantidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de horas de bloques temporales del proyecto\n",
    "time=plplin['time'].max()\n",
    "\n",
    "# Número de barras\n",
    "nbus=len(indexbus['id'])\n",
    "lbus=list(indexbus['id'])\n",
    "\n",
    "# Número de generadores\n",
    "ngen=len(indexcen['id'])\n",
    "\n",
    "# Número de lineas\n",
    "nlin=len(indexlin['id'])\n",
    "\n",
    "# Número de Reservoirs\n",
    "#nres = len(reservoirs['EmbName'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función generadora de latitudes y longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aleatory_direction():\n",
    "    latitud=-random.uniform(10, 85)\n",
    "    longitud=-random.uniform(10, 85)\n",
    "    return latitud,longitud\n",
    "\n",
    "def LatLon_To_XY(Lat,Lon):\n",
    "  B = pyproj.Transformer.from_crs(4326,20049) #WGS84->EPSG:20049 (Chile 2021/UTM zone 19S)\n",
    "  UTMx, UTMy = B.transform(Lat,Lon)\n",
    "  return UTMx, UTMy\n",
    "\n",
    "def XY_To_LatLon(x,y):\n",
    "  B = pyproj.Transformer.from_crs(20049,4326)\n",
    "  Lat, Lon = B.transform(x,y)\n",
    "  return Lat, Lon\n",
    "\n",
    "def valorXY(LatP, LonP, scale):\n",
    "  A = LatLon_To_XY(LatP, LonP)\n",
    "  X,Y = A[0]*scale, A[1]*scale\n",
    "  return Y,X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloques a Fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Año'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m indhor2\u001b[39m=\u001b[39mindhor\u001b[39m.\u001b[39;49mdrop(\u001b[39m'\u001b[39;49m\u001b[39mHora\u001b[39;49m\u001b[39m'\u001b[39;49m,axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mAño\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mMes\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      2\u001b[0m indhorlist\u001b[39m=\u001b[39m[]\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m indhor2:\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:7718\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7713\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   7715\u001b[0m \u001b[39m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[0;32m   7716\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   7717\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 7718\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   7719\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   7720\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m   7721\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   7722\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   7723\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[0;32m   7724\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   7725\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   7726\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7727\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   7728\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   7729\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[0;32m    883\u001b[0m         obj,\n\u001b[0;32m    884\u001b[0m         keys,\n\u001b[0;32m    885\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    886\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    887\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    888\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m    889\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[0;32m    890\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[0;32m    894\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    880\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 882\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    883\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Año'"
     ]
    }
   ],
   "source": [
    "indhor2=indhor.drop('Hora',axis=1).groupby(['Año','Mes'])\n",
    "indhorlist=[]\n",
    "for x in indhor2:\n",
    "    indhorlist.append([str(x[1]['Bloque'].min()),str(x[1]['Bloque'].max()),str(x[0])])\n",
    "with open( namedata+'/Scenarios/indhor.json', 'w') as f:\n",
    "  json.dump(indhorlist, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación por Sistema por Hidrología"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim1 lista\n"
     ]
    }
   ],
   "source": [
    "typegenlist=typecentrals.cen_type.unique()\n",
    "for i,hydro in enumerate(hidrolist):\n",
    "    print(hydro+\" lista\")\n",
    "    dic_type_gen={}\n",
    "    auxdf = plpcen[plpcen['Hidro']==hydro]\n",
    "    auxdf=auxdf.groupby(['tipo','time'])['CenPgen'].sum().reset_index().groupby('tipo')\n",
    "    for group in auxdf:\n",
    "        tipo = group[0]\n",
    "        df_tipo = group[1]\n",
    "        dic_type_gen[tipo] = [row for row in df_tipo[['time', 'CenPgen']].to_dict(orient='records')]\n",
    "\n",
    "    \n",
    "    with open(generation_sistem_path+f'/generation_system_{i+1}.json', 'w') as f:\n",
    "        json.dump(dic_type_gen, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentiles Costo Marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando datos de AltoNorte110 [1/214]\n",
      "Procesando datos de Andes220 [2/214]\n",
      "Procesando datos de Andes345 [3/214]\n",
      "Procesando datos de Angamos220 [4/214]\n",
      "Procesando datos de Antofagasta110 [5/214]\n",
      "Procesando datos de Arica066 [6/214]\n",
      "Procesando datos de Atacama220_BP1 [7/214]\n",
      "Procesando datos de Barriles220 [8/214]\n",
      "Procesando datos de Cachiyuyal220 [9/214]\n",
      "Procesando datos de Capricornio110 [10/214]\n",
      "Procesando datos de Capricornio220 [11/214]\n",
      "Procesando datos de Cardones110 [12/214]\n",
      "Procesando datos de Cardones220 [13/214]\n",
      "Procesando datos de Chacaya220 [14/214]\n",
      "Procesando datos de Chuquicamata100 [15/214]\n",
      "Procesando datos de Chuquicamata220 [16/214]\n",
      "Procesando datos de Cochrane220 [17/214]\n",
      "Procesando datos de Collahuasi220 [18/214]\n",
      "Procesando datos de Conchi220 [19/214]\n",
      "Procesando datos de Condores220 [20/214]\n",
      "Procesando datos de CPinto220 [21/214]\n",
      "Procesando datos de Crucero220 [22/214]\n",
      "Procesando datos de Cumbres500 [23/214]\n",
      "Procesando datos de DAlmagro110 [24/214]\n",
      "Procesando datos de DAlmagro220 [25/214]\n",
      "Procesando datos de DArica066 [26/214]\n",
      "Procesando datos de Desalant110 [27/214]\n",
      "Procesando datos de Domeyko220 [28/214]\n",
      "Procesando datos de DonaCarmen220 [29/214]\n",
      "Procesando datos de DonGoyo220 [30/214]\n",
      "Procesando datos de DonHector220 [31/214]\n",
      "Procesando datos de ElCobre220 [32/214]\n",
      "Procesando datos de ElLoa220 [33/214]\n",
      "Procesando datos de ElNegro110 [34/214]\n",
      "Procesando datos de ElPenon110 [35/214]\n",
      "Procesando datos de ElTesoro220 [36/214]\n",
      "Procesando datos de Esmeralda110 [37/214]\n",
      "Procesando datos de Esmeralda220 [38/214]\n",
      "Procesando datos de Esperanza220 [39/214]\n",
      "Procesando datos de Francisco220 [40/214]\n",
      "Procesando datos de Guacolda220 [41/214]\n",
      "Procesando datos de Huasco110 [42/214]\n",
      "Procesando datos de Kapatur220_BP1 [43/214]\n",
      "Procesando datos de Laberinto220 [44/214]\n",
      "Procesando datos de LaCebada220 [45/214]\n",
      "Procesando datos de LaCruz220 [46/214]\n",
      "Procesando datos de Lagunas220 [47/214]\n",
      "Procesando datos de LaNegra110 [48/214]\n",
      "Procesando datos de LosChangos220 [49/214]\n",
      "Procesando datos de LosChangos500 [50/214]\n",
      "Procesando datos de LPalmas220 [51/214]\n",
      "Procesando datos de LVilos220 [52/214]\n",
      "Procesando datos de Maitencillo110 [53/214]\n",
      "Procesando datos de Maitencillo220 [54/214]\n",
      "Procesando datos de Mantos220 [55/214]\n",
      "Procesando datos de MariaElena220 [56/214]\n",
      "Procesando datos de Mejillones110 [57/214]\n"
     ]
    }
   ],
   "source": [
    "def percentilCM():\n",
    "    datos_bar = plpbar[['Hidro', 'time','id', 'BarName', 'CMgBar']]\n",
    "    lista_bar = datos_bar.BarName.unique()\n",
    "\n",
    "    i=1\n",
    "    for barra in lista_bar:\n",
    "        print(f'Procesando datos de {barra} [{i}/{len(lista_bar)}]')\n",
    "        data_barraTx = datos_bar.loc[(datos_bar.BarName == barra)]\n",
    "        idbar=data_barraTx['id'].unique()[0]\n",
    "        data_barraTx = data_barraTx[~(data_barraTx['Hidro'] == 'MEDIA')]\n",
    "        Promedio = data_barraTx[['time','CMgBar']]\n",
    "        xy =Promedio.groupby(['time']).mean()\n",
    "        \n",
    "        data_barraTx = data_barraTx.groupby(['time']).agg(perc0=('CMgBar', lambda x: x.quantile(0.0)),\n",
    "                                                                perc20=(\n",
    "                                                                    'CMgBar', lambda x: x.quantile(0.2)),\n",
    "                                                                perc80=(\n",
    "                                                                    'CMgBar', lambda x: x.quantile(0.8)),\n",
    "                                                                perc100=('CMgBar', lambda x: x.quantile(1)))\n",
    "\n",
    "        data_barraTx['promedio'] = xy\n",
    "        data_barraTx = data_barraTx.assign(name=barra)\n",
    "        data_barraTx = data_barraTx.assign(id=idbar)\n",
    "        data_barraTx.reset_index(inplace=True)\n",
    "        data_barraTx=data_barraTx[['id','time','name','perc0','perc20','perc80','perc100','promedio']]\n",
    "        data_barraTx.to_json(marginal_cost_path+f\"/bus_{idbar}.json\",orient='records')\n",
    "        i=i+1\n",
    "percentilCM()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentiles Flujos de Lineas de Transmisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando datos de Andes220->Oeste220 [1/325]\n",
      "Procesando datos de Andes345->Andes220 [2/325]\n",
      "Procesando datos de Angamos220->Kapatur220 [3/325]\n",
      "Procesando datos de Antofag110->Desalant110 [4/325]\n",
      "Procesando datos de Antofag110->LaNegra110 [5/325]\n",
      "Procesando datos de Atacama220->OHiggins220 [6/325]\n",
      "Procesando datos de Cachiyuyal220->DAlmagro220 [7/325]\n",
      "Procesando datos de Capricorn220->Capricorn110 [8/325]\n",
      "Procesando datos de Capricornio110->Antofag110 [9/325]\n",
      "Procesando datos de Capricornio110->ElNegro110 [10/325]\n",
      "Procesando datos de Capricornio110->LaNegra110 [11/325]\n",
      "Procesando datos de Capricornio220->Mantos220 [12/325]\n",
      "Procesando datos de Cardones220->Cardones110 [13/325]\n",
      "Procesando datos de Cardones220->CPinto220 [14/325]\n",
      "Procesando datos de Chacaya220->Capricornio220 [15/325]\n",
      "Procesando datos de Chacaya220->ElCobre220 [16/325]\n",
      "Procesando datos de Chacaya220->Mejillones220 [17/325]\n",
      "Procesando datos de Chuqui220->Chuqui100 [18/325]\n",
      "Procesando datos de Chuquicamata100->S-AA100 [19/325]\n",
      "Procesando datos de Chuquicamata100->S-Km6100 [20/325]\n",
      "Procesando datos de Cochrane220->Encuentro220 [21/325]\n",
      "Procesando datos de Condores220->PAlmonte220 [22/325]\n",
      "Procesando datos de Crucero220->Barriles220 [23/325]\n",
      "Procesando datos de Crucero220->Chacaya220 [24/325]\n",
      "Procesando datos de Crucero220->Chuquicamata220 [25/325]\n",
      "Procesando datos de Crucero220->Conchi220 [26/325]\n",
      "Procesando datos de Crucero220->ElLoa220 [27/325]\n",
      "Procesando datos de Crucero220->Laberinto220 [28/325]\n",
      "Procesando datos de Crucero220->LaCruz220 [29/325]\n",
      "Procesando datos de Crucero220->MariaElena220 [30/325]\n",
      "Procesando datos de Crucero220->Salar220 [31/325]\n",
      "Procesando datos de Crucero220->Tocopilla220 [32/325]\n",
      "Procesando datos de Cumbre500_SC->NvaCardones500_SC [33/325]\n",
      "Procesando datos de Cumbre500->NvaCardones500 [34/325]\n",
      "Procesando datos de DAlmagro220->DAlmagro110 [35/325]\n",
      "Procesando datos de DArica066->Arica066 [36/325]\n",
      "Procesando datos de Arica066->PAlmonte110 [37/325]\n",
      "Procesando datos de DonaCarmen220->Nogales220_aux [38/325]\n",
      "Procesando datos de DonGoyo220->LaCebada220 [39/325]\n",
      "Procesando datos de DonGoyo220->Talinay220 [40/325]\n",
      "Procesando datos de DonHector220->PColorada220 [41/325]\n",
      "Procesando datos de ElCobre220->Esperanza220 [42/325]\n",
      "Procesando datos de ElLoa220->Tocopilla220 [43/325]\n",
      "Procesando datos de ElNegro110->AltoNorte110 [44/325]\n",
      "Procesando datos de ElTesoro220->Esperanza220 [45/325]\n",
      "Procesando datos de Encuentro220->Colla220 [46/325]\n",
      "Procesando datos de Encuentro220->ElTesoro220 [47/325]\n",
      "Procesando datos de Encuentro220->Lagunas220 [48/325]\n",
      "Procesando datos de Encuentro220->Miraje220 [49/325]\n",
      "Procesando datos de Esmeralda110->Portada110 [50/325]\n",
      "Procesando datos de Esmeralda220->Esmeralda110 [51/325]\n",
      "Procesando datos de Francisco220->DAlmagro220 [52/325]\n",
      "Procesando datos de GasAta220->Esmeralda220 [53/325]\n",
      "Procesando datos de Guacolda220->Maitenc220 [54/325]\n",
      "Procesando datos de Illapa220->Cumbre500 [55/325]\n",
      "Procesando datos de Illapa220->DAlmagro220 [56/325]\n",
      "Procesando datos de Kapatur220->Laberinto220 [57/325]\n",
      "Procesando datos de Kapatur220->Ohiggins220 [58/325]\n",
      "Procesando datos de Laberinto220->ElCobre220 [59/325]\n",
      "Procesando datos de Laberinto220->Mantos220 [60/325]\n",
      "Procesando datos de Laberinto220->NvaZald220 [61/325]\n",
      "Procesando datos de Laberinto220->Oeste220 [62/325]\n",
      "Procesando datos de LaCebada220->MRedondo220 [63/325]\n",
      "Procesando datos de LaCebada220->PuntaSierra220 [64/325]\n",
      "Procesando datos de Lagunas220->Collahuasi220 [65/325]\n",
      "Procesando datos de Lagunas220->NvaVictoria220 [66/325]\n",
      "Procesando datos de Lagunas220->Tarapaca220 [67/325]\n",
      "Procesando datos de LaNegra110->AltoNorte110 [68/325]\n",
      "Procesando datos de LosChangos220->Kapatur220 [69/325]\n",
      "Procesando datos de LosChangos500->Cumbre500 [70/325]\n",
      "Procesando datos de LosChangos500->Parinas500 [71/325]\n",
      "Procesando datos de Parinas500->Cumbre500 [72/325]\n",
      "Procesando datos de Likanantai500->Parinas500 [73/325]\n",
      "Procesando datos de LosChangos500->Kimal500_I [74/325]\n",
      "Procesando datos de LosChangos500->Kimal500_II [75/325]\n",
      "Procesando datos de LosChangos500->LosChangos220 [76/325]\n",
      "Procesando datos de LPalmas220->LVilos220 [77/325]\n",
      "Procesando datos de LVilos220->DonaCarmen220 [78/325]\n",
      "Procesando datos de LVilos220->Nogales220_aux [79/325]\n",
      "Procesando datos de Maitenc110->Cardones110 [80/325]\n",
      "Procesando datos de Maitenc110->Huasco110 [81/325]\n",
      "Procesando datos de Maitenc220->Cardones220 [82/325]\n",
      "Procesando datos de Maitenc220->DonHector220 [83/325]\n",
      "Procesando datos de Maitenc220->Maitenc110 [84/325]\n",
      "Procesando datos de Maitencillo220->PColorada220_II [85/325]\n",
      "Procesando datos de MariaElena220->Lagunas220 [86/325]\n",
      "Procesando datos de MariaElena220->NvaVictoria220 [87/325]\n",
      "Procesando datos de Mauro220->Quillota220 [88/325]\n",
      "Procesando datos de Mejillones110->Pampa110 [89/325]\n",
      "Procesando datos de Mejillones220->Mejillones110 [90/325]\n",
      "Procesando datos de Mejillones220->OHiggins220 [91/325]\n",
      "Procesando datos de Miraje220->Atacama220 [92/325]\n",
      "Procesando datos de Miraje220->TOEnlace220 [93/325]\n",
      "Procesando datos de MRedondo220->PuntaSierra220 [94/325]\n",
      "Procesando datos de Norgener220->Barriles220 [95/325]\n",
      "Procesando datos de Norgener220->LaCruz220 [96/325]\n",
      "Procesando datos de NvaCardones500->Cardones220 [97/325]\n",
      "Procesando datos de NvaMaitenc500->Maitenc220 [98/325]\n",
      "Procesando datos de NvaMaitenc500->NvaCardones500 [99/325]\n",
      "Procesando datos de NvaPAzucar500_SC->NvaMaitenc500_SC [100/325]\n",
      "Procesando datos de NvaPAzucar500_SC->Polpaico500_I_SC [101/325]\n",
      "Procesando datos de NvaPAzucar500_SC->Polpaico500_II_SC [102/325]\n",
      "Procesando datos de NvaPAzucar500->NvaMaitenc500 [103/325]\n",
      "Procesando datos de NvaPAzucar500->PAzucar220 [104/325]\n",
      "Procesando datos de NvaPAzucar500->Polpaico500_I [105/325]\n",
      "Procesando datos de NvaPAzucar500->Polpaico500_II [106/325]\n",
      "Procesando datos de NvaZaldivar220->Andes220 [107/325]\n",
      "Procesando datos de NvaZaldivar220->Domeyko220 [108/325]\n",
      "Procesando datos de OHiggins220->Domeyko220 [109/325]\n",
      "Procesando datos de OHiggins220->Palestina220 [110/325]\n",
      "Procesando datos de Palestina220->Domeyko220 [111/325]\n",
      "Procesando datos de PAlmonte220->Lagunas220 [112/325]\n",
      "Procesando datos de PAlmonte220->PAlmonte110 [113/325]\n",
      "Procesando datos de Pampa110->Desalant110 [114/325]\n",
      "Procesando datos de Paposo220->Cachiyuyal220 [115/325]\n",
      "Procesando datos de Paposo220->Francisco220 [116/325]\n",
      "Procesando datos de PAzucar110->ElPenon110 [117/325]\n",
      "Procesando datos de PAzucar110->Maitenc110 [118/325]\n",
      "Procesando datos de PAzucar220_aux->DonGoyo220 [119/325]\n",
      "Procesando datos de PAzucar220->PAzucar110 [120/325]\n",
      "Procesando datos de PAzucar220->PuntaSierra220 [121/325]\n",
      "Procesando datos de PColorada220->PAzucar220 [122/325]\n",
      "Procesando datos de PColorada220->PAzucar220_II [123/325]\n",
      "Procesando datos de PuntaSierra220->LPalmas220 [124/325]\n",
      "Procesando datos de PuntaSierra220->Mauro220 [125/325]\n",
      "Procesando datos de Salar110->Salar220 [126/325]\n",
      "Procesando datos de Salar220->Chuquicamata220 [127/325]\n",
      "Procesando datos de SalardelCarmen [128/325]\n",
      "Procesando datos de Salta345->Andes345 [129/325]\n",
      "Procesando datos de S-Km6100->Salar110 [130/325]\n",
      "Procesando datos de Talinay220->LaCebada220 [131/325]\n",
      "Procesando datos de Tamaya110->S-AA100_3B [132/325]\n",
      "Procesando datos de Tamaya110->Salar110_4B [133/325]\n",
      "Procesando datos de Tarapaca220->Condores220 [134/325]\n",
      "Procesando datos de TO_Enlace220->Atacama220 [135/325]\n",
      "Procesando datos de Tocopilla110->S-AA100 [136/325]\n",
      "Procesando datos de Tocopilla110->Tamaya110 [137/325]\n",
      "Procesando datos de Tocopilla220->Tocopi110 [138/325]\n",
      "Procesando datos de AJahuel110->Sauzal110_BP1 [139/325]\n",
      "Procesando datos de AJahuel154->Paine154 [140/325]\n",
      "Procesando datos de AJahuel154->Tuniche154_II [141/325]\n",
      "Procesando datos de AJahuel220->AJahuel110 [142/325]\n",
      "Procesando datos de AJahuel220->AJahuel154 [143/325]\n",
      "Procesando datos de AJahuel220->Buin110 [144/325]\n",
      "Procesando datos de AJahuel220->Chena220 [145/325]\n",
      "Procesando datos de AJahuel220->PAltoCmpc110 [146/325]\n",
      "Procesando datos de AJahuel220->SantaMarta220 [147/325]\n",
      "Procesando datos de AJahuel500->AJahuel220 [148/325]\n",
      "Procesando datos de Alfalfal220->Almendros220 [149/325]\n",
      "Procesando datos de Almendros110->Apoquindo110 [150/325]\n",
      "Procesando datos de Almendros220->AJahuel220 [151/325]\n",
      "Procesando datos de Almendros220->Almendros110 [152/325]\n",
      "Procesando datos de AMelipill220->LoAguirre220 [153/325]\n",
      "Procesando datos de Ancoa220->Itahue154 [154/325]\n",
      "Procesando datos de Ancoa500->AJahuel500 [155/325]\n",
      "Procesando datos de Ancoa500->Ancoa220 [156/325]\n",
      "Procesando datos de Angostura220->Mulchen220 [157/325]\n",
      "Procesando datos de Antuco220->Charrua220 [158/325]\n",
      "Procesando datos de Antuco220->Trupan220 [159/325]\n",
      "Procesando datos de Apoquindo110->ElSalto110 [160/325]\n",
      "Procesando datos de ASanta110->Mirafl110 [161/325]\n",
      "Procesando datos de ASanta220->ASanta110 [162/325]\n",
      "Procesando datos de ASanta220->ASanta110_2 [163/325]\n",
      "Procesando datos de Batuco110->PPeuco110 [164/325]\n",
      "Procesando datos de Batuco110->PPeuco110_I [165/325]\n",
      "Procesando datos de Bocamina154->Coronel154 [166/325]\n",
      "Procesando datos de Buin110->LoEspejo110 [167/325]\n",
      "Procesando datos de Candela220->AJahuel220 [168/325]\n",
      "Procesando datos de Canutilla220->PMontt220 [169/325]\n",
      "Procesando datos de Cautin220->RioTolten220 [170/325]\n",
      "Procesando datos de Charrua066->Cholguan066 [171/325]\n",
      "Procesando datos de Charrua154->Charrua066 [172/325]\n",
      "Procesando datos de Charrua154->Chillan154 [173/325]\n",
      "Procesando datos de Charrua154->Conce154 [174/325]\n",
      "Procesando datos de Charrua154->Parral154 [175/325]\n",
      "Procesando datos de Charrua220->Charrua154 [176/325]\n",
      "Procesando datos de Charrua220->Charrua500 [177/325]\n",
      "Procesando datos de Charrua220->Conce154 [178/325]\n",
      "Procesando datos de Charrua220Aux->Duqueco220 [179/325]\n",
      "Procesando datos de Charrua220->EntreRios220 [180/325]\n",
      "Procesando datos de Charrua220->Hualpen220 [181/325]\n",
      "Procesando datos de Charrua220->Lagunillas220 [182/325]\n",
      "Procesando datos de Charrua220Aux->Mulchen220 [183/325]\n",
      "Procesando datos de Charrua220->Ralco220 [184/325]\n",
      "Procesando datos de Charrua500->Ancoa500AuxS [185/325]\n",
      "Procesando datos de Chena110->LoEspejo110 [186/325]\n",
      "Procesando datos de Chena220->Chena110 [187/325]\n",
      "Procesando datos de Chillan154->SantaElvira066 [188/325]\n",
      "Procesando datos de Chiloe110->Degan110 [189/325]\n",
      "Procesando datos de Chiloe110->Pid-Pid110 [190/325]\n",
      "Procesando datos de Chiloe220->Chiloe110 [191/325]\n",
      "Procesando datos de Cholguan220->Charrua220 [192/325]\n",
      "Procesando datos de Cipreses154->Itahue154 [193/325]\n",
      "Procesando datos de Ciruelos220->Pichirropulli220Aux [194/325]\n",
      "Procesando datos de Ciruelos220->Valdivia220 [195/325]\n",
      "Procesando datos de CNavia110->Batuco110 [196/325]\n",
      "Procesando datos de CNavia110->Batuco110_I [197/325]\n",
      "Procesando datos de CNavia110->Chena110 [198/325]\n",
      "Procesando datos de CNavia110->LVegas110_exp [199/325]\n",
      "Procesando datos de CNavia220_Aux_D->Polpaico220 [200/325]\n",
      "Procesando datos de CNavia220->Chena220 [201/325]\n",
      "Procesando datos de CNavia220->CNavia110 [202/325]\n",
      "Procesando datos de CNavia220->CNavia220_Aux_D [203/325]\n",
      "Procesando datos de Colbun220->Ancoa220 [204/325]\n",
      "Procesando datos de Colbun220->PNegro220 [205/325]\n",
      "Procesando datos de Conce154->Conce066 [206/325]\n",
      "Procesando datos de Conce154->SVicente154 [207/325]\n",
      "Procesando datos de Coronel066->Guindo066 [208/325]\n",
      "Procesando datos de Coronel154->Coronel066 [209/325]\n",
      "Procesando datos de Coronel154->Horcones066 [210/325]\n",
      "Procesando datos de Duqueco220->Temuco220 [211/325]\n",
      "Procesando datos de ElSalto110->SCristobal110 [212/325]\n",
      "Procesando datos de EntreRios500->Ancoa500AuxS [213/325]\n",
      "Procesando datos de EntreRios500->Charrua500 [214/325]\n",
      "Procesando datos de EntreRios500->EntreRios220 [215/325]\n",
      "Procesando datos de Florida110->Almendros110 [216/325]\n",
      "Procesando datos de Florida110->StaRosa110 [217/325]\n",
      "Procesando datos de Fopaco154->Lagunillas154 [218/325]\n",
      "Procesando datos de Guindo066->Concepcio066 [219/325]\n",
      "Procesando datos de Guindo220->Guindo066 [220/325]\n",
      "Procesando datos de Guindo220->Hualpen220 [221/325]\n",
      "Procesando datos de Hualpen154->Mapal154 [222/325]\n",
      "Procesando datos de Hualpen220->Hualpen154 [223/325]\n",
      "Procesando datos de Itahue154->Maule154 [224/325]\n",
      "Procesando datos de Itahue154->Teno154 [225/325]\n",
      "Procesando datos de Itahue220->Maule220 [226/325]\n",
      "Procesando datos de Lagunillas154->Coronel154 [227/325]\n",
      "Procesando datos de Lagunilla220->Guindo220 [228/325]\n",
      "Procesando datos de Lagunillas220->Lagunillas154 [229/325]\n",
      "Procesando datos de Linares154->SJavier066 [230/325]\n",
      "Procesando datos de LoAguirre220->CNavia220 [231/325]\n",
      "Procesando datos de LoAguirre500->AJahuel500 [232/325]\n",
      "Procesando datos de LoAguirre500->LoAguirre220 [233/325]\n",
      "Procesando datos de LoAguirre500->LoAguirre220_2 [234/325]\n",
      "Procesando datos de LoAguirre500->Polpaico500 [235/325]\n",
      "Procesando datos de LoEspejo110->Ochagavia110 [236/325]\n",
      "Procesando datos de Malloa154->Tinguiririca154 [237/325]\n",
      "Procesando datos de Mapal154->Fopaco154 [238/325]\n",
      "Procesando datos de Maule154->Linares154 [239/325]\n",
      "Procesando datos de Maule154->SMiguel066 [240/325]\n",
      "Procesando datos de Mulchen220->Cautin220 [241/325]\n",
      "Procesando datos de Nogales220->Polpaico220 [242/325]\n",
      "Procesando datos de Nogales220->Quillota220 [243/325]\n",
      "Procesando datos de Nogales220->Ventanas220 [244/325]\n",
      "Procesando datos de Ochagavia110->Florida110 [245/325]\n",
      "Procesando datos de Pachacama110->LVegas110 [246/325]\n",
      "Procesando datos de Paine154->Tuniche154_I [247/325]\n",
      "Procesando datos de Pangue220->Cholguan220 [248/325]\n",
      "Procesando datos de Pangue220->Trupan220 [249/325]\n",
      "Procesando datos de Parral154->Linares154 [250/325]\n",
      "Procesando datos de Pehuenche220->Ancoa220 [251/325]\n",
      "Procesando datos de Petroquim154->Hualpen154 [252/325]\n",
      "Procesando datos de Pichirropulli220->Tineo220 [253/325]\n",
      "Procesando datos de Pid-Pid110->Chonchi110 [254/325]\n",
      "Procesando datos de Pillanlelbun066->Lautaro066 [255/325]\n",
      "Procesando datos de PMontt220->Chiloe220 [256/325]\n",
      "Procesando datos de Tineo220->Chiloe220 [257/325]\n",
      "Procesando datos de PMontt220->Molinos110 [258/325]\n",
      "Procesando datos de PNegro220->Candela220 [259/325]\n",
      "Procesando datos de PNegro220->Tinguiririca220 [260/325]\n",
      "Procesando datos de Polpaico220->ElSalto110 [261/325]\n",
      "Procesando datos de Polpaico500->Polpaico220 [262/325]\n",
      "Procesando datos de PPeuco110->LVegas110 [263/325]\n",
      "Procesando datos de PPeuco110->LVegas110_I [264/325]\n",
      "Procesando datos de Prrahue220->Rahue220 [265/325]\n",
      "Procesando datos de Prropulli220AuxS->Prrahue220 [266/325]\n",
      "Procesando datos de Prropulli220AuxS->Rahue220 [267/325]\n",
      "Procesando datos de Quillota110->Mirafl110 [268/325]\n",
      "Procesando datos de Quillota110->Pachacam110 [269/325]\n",
      "Procesando datos de Quillota220->Polpaico220 [270/325]\n",
      "Procesando datos de Quillota220->Quillota110 [271/325]\n",
      "Procesando datos de Quintero220->SanLuis220 [272/325]\n",
      "Procesando datos de Rahue220->Tineo220 [273/325]\n",
      "Procesando datos de Tineo220->PMontt220 [274/325]\n",
      "Procesando datos de Rancagua154->Tuniche154_I [275/325]\n",
      "Procesando datos de Rancagua154->Tuniche154_II [276/325]\n",
      "Procesando datos de Rapel220->AMelipill220 [277/325]\n",
      "Procesando datos de Renca110->CNavia110 [278/325]\n",
      "Procesando datos de RioTolten220->Ciruelos220 [279/325]\n",
      "Procesando datos de Rucue220->Charrua220 [280/325]\n",
      "Procesando datos de SanLuis220->ASanta220 [281/325]\n",
      "Procesando datos de SanLuis220->Quillota220 [282/325]\n",
      "Procesando datos de SantaMaria220->Charrua220 [283/325]\n",
      "Procesando datos de SantaMarta220->Chena220 [284/325]\n",
      "Procesando datos de Sauzal110_2->Sauzal154 [285/325]\n",
      "Procesando datos de Sauzal154->Rancagua154 [286/325]\n",
      "Procesando datos de SCristobal110->CNavia110 [287/325]\n",
      "Procesando datos de SFcoMost066->Paine154 [288/325]\n",
      "Procesando datos de SJavier66->Constituci66 [289/325]\n",
      "Procesando datos de SMiguel66->Talca66 [290/325]\n",
      "Procesando datos de StaRosa110->AJahuel110 [291/325]\n",
      "Procesando datos de SVicente154->Hualpen154 [292/325]\n",
      "Procesando datos de SVicente154->Petroq154 [293/325]\n",
      "Procesando datos de Talca66->SJavier66 [294/325]\n",
      "Procesando datos de Temuco220->Cautin220 [295/325]\n",
      "Procesando datos de Temuco220->Temuco66 [296/325]\n",
      "Procesando datos de Temuco66->Pillanlelbun66 [297/325]\n",
      "Procesando datos de Tilcoco154->Malloa154 [298/325]\n",
      "Procesando datos de Tilcoco154->PCortes154 [299/325]\n",
      "Procesando datos de Tinguiririca154->Itahue154 [300/325]\n",
      "Procesando datos de Tinguiririca154->Teno154 [301/325]\n",
      "Procesando datos de Tinguiririca220->Tinguiririca154 [302/325]\n",
      "Procesando datos de Torquemada110->Mirafl110 [303/325]\n",
      "Procesando datos de Trupan220->Charrua220 [304/325]\n",
      "Procesando datos de Tuniche_1->PCortes154 [305/325]\n",
      "Procesando datos de Tuniche_1->Tinguiririca154 [306/325]\n",
      "Procesando datos de Tuniche_2->PCortes154 [307/325]\n",
      "Procesando datos de Valdivia220->Pichirropulli220Aux [308/325]\n",
      "Procesando datos de Ventanas110->Mirafl110 [309/325]\n",
      "Procesando datos de Ventanas110->Quillota110 [310/325]\n",
      "Procesando datos de Ventanas110->Torquemada110 [311/325]\n",
      "Procesando datos de Ventanas220->Ventanas110 [312/325]\n",
      "Procesando datos de PAzucar220->PAzucar220_aux [313/325]\n",
      "Procesando datos de PAzucar220->PAzucar220_aux2 [314/325]\n",
      "Procesando datos de Nogales220aux->Nogales220 [315/325]\n",
      "Procesando datos de Ancoa500AuxS->Ancoa500 [316/325]\n",
      "Procesando datos de Pichirropulli220->Pichirropulli220AuxS [317/325]\n",
      "Procesando datos de Pichirropulli220Aux->Pichirropulli220 [318/325]\n",
      "Procesando datos de Charrua220->Charrua220Aux [319/325]\n",
      "Procesando datos de ASanta220->AMelipilla220 [320/325]\n",
      "Procesando datos de Itahue154->NvaNirivilo220 [321/325]\n",
      "Procesando datos de NvaNirivilo220->NvaCauquenes220 [322/325]\n",
      "Procesando datos de NvaCauquenes220->Lagunillas220 [323/325]\n",
      "Procesando datos de NvaNirivilo220->Constitucion066 [324/325]\n",
      "Procesando datos de NvaCauquenes220->Parral154 [325/325]\n"
     ]
    }
   ],
   "source": [
    "def percentilFL():\n",
    "    datos_lineas=plplin[['id','Hidro', 'time', 'LinName', 'LinFluP', 'capacity']]\n",
    "    lista_lineas = datos_lineas.LinName.unique()\n",
    "    n_lineas = len(lista_lineas)\n",
    "    i=1\n",
    "    for linea in lista_lineas:\n",
    "        print(f'Procesando datos de {linea} [{i}/{n_lineas}]')\n",
    "        data_lineaTx = datos_lineas.loc[(datos_lineas.LinName == linea)]\n",
    "        idlin=data_lineaTx['id'].unique()[0]\n",
    "        data_lineaTx = data_lineaTx[~(data_lineaTx['Hidro'] == 'MEDIA')]\n",
    "        fluMax = data_lineaTx[['time','capacity']]\n",
    "        xy =-fluMax.groupby(['time']).max()\n",
    "        data_lineaTx = data_lineaTx.groupby(['time']).agg(perc0=('LinFluP', lambda x: x.quantile(0.0)),\n",
    "                                                                perc20=(\n",
    "                                                                    'LinFluP', lambda x: x.quantile(0.2)),\n",
    "                                                                perc80=(\n",
    "                                                                    'LinFluP', lambda x: x.quantile(0.8)),\n",
    "                                                                perc100=('LinFluP', lambda x: x.quantile(1)))\n",
    "\n",
    "        data_lineaTx['Min'] = xy\n",
    "        data_lineaTx['Max'] = -xy\n",
    "        i = i+1\n",
    "        data_lineaTx.reset_index(inplace=True)\n",
    "        data_lineaTx = data_lineaTx.assign(id=idlin)\n",
    "        data_lineaTx = data_lineaTx.assign(LinName = linea)\n",
    "        data_lineaTx.to_json(line_flow_percentil_path+f\"/line_{idlin}.json\",orient='records')\n",
    "percentilFL()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenarios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando scenarios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.666666666666667% Completado\n",
      "13.333333333333334% Completado\n",
      "20.0% Completado\n",
      "26.666666666666668% Completado\n",
      "33.33333333333333% Completado\n",
      "40.0% Completado\n",
      "46.666666666666664% Completado\n",
      "53.333333333333336% Completado\n",
      "60.0% Completado\n",
      "66.66666666666666% Completado\n",
      "73.33333333333333% Completado\n",
      "80.0% Completado\n",
      "86.66666666666667% Completado\n",
      "93.33333333333333% Completado\n",
      "100.0% Completado\n"
     ]
    }
   ],
   "source": [
    "# Bus contiene:\n",
    "'''\n",
    "\t\t(*) id <int>: identificador de la barra \n",
    "\t\t(*) time <int>: instante de registro\n",
    "\t\t(*) name <str>: nombre de la barra\n",
    "\t\tmarginal_cost <float>: costo marginal, genera el gráfico de costo\n",
    "\t\t\t\t\t[USD/MWh]\n",
    "\t\tDemBarE <float>: construye el gráfico de demanda de Energía [MWh]\n",
    "\t\tDemBarP <float>: construye el gráfico de demanda de Potencia [MW]\n",
    "\t\tValue <float>: mismo valor que marginal_cost [MWh]\n",
    "'''\n",
    "def busscenariofunction(dfbusauxlist, pathbus):\n",
    "    for x in range(nbus): \n",
    "        idbus = indexbus['id'][x]\n",
    "        aux = pd.DataFrame({\n",
    "            'id': idbus,\n",
    "            'time': dfbusauxlist[x]['time'],\n",
    "            'name': indexbus['BarName'][x],\n",
    "            'marginal_cost': dfbusauxlist[x]['CMgBar'],\n",
    "            'value': dfbusauxlist[x]['CMgBar'],\n",
    "            'DemBarE': dfbusauxlist[x]['DemBarE'],\n",
    "            'DemBarP': dfbusauxlist[x]['DemBarP'],\n",
    "            'BarRetP': dfbusauxlist[x]['BarRetP']\n",
    "        })\n",
    "        aux.to_json(pathbus + f\"/bus_{idbus}.json\", orient='records')\n",
    "\n",
    "for hidronum,hidroname in enumerate(hidrolist):\n",
    "\tdfbussauxx=plpbar.query(f\"(Hidro=='{hidroname}')\").reset_index()\n",
    "\tdfbuslist=[]\n",
    "\tfor x in lbus:\n",
    "\t\tidaux=x\n",
    "\t\tdfbuslist.append(dfbussauxx[dfbussauxx.id==idaux].reset_index(drop=True))\n",
    "\tprint(f\"{((hidronum+1)/len(hidrolist))*100}% Completado\")\n",
    "\tbusscenariofunction(dfbuslist,busscenariolist[hidronum])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.666666666666667% Completado\n",
      "13.333333333333334% Completado\n",
      "20.0% Completado\n",
      "26.666666666666668% Completado\n",
      "33.33333333333333% Completado\n",
      "40.0% Completado\n",
      "46.666666666666664% Completado\n",
      "53.333333333333336% Completado\n",
      "60.0% Completado\n",
      "66.66666666666666% Completado\n",
      "73.33333333333333% Completado\n",
      "80.0% Completado\n",
      "86.66666666666667% Completado\n",
      "93.33333333333333% Completado\n",
      "100.0% Completado\n"
     ]
    }
   ],
   "source": [
    "# Centrals contiene:\n",
    "'''\n",
    "\t\t(*) id <int>: identificador del generador\n",
    "\t\t(*) time <int>: instante de registro\n",
    "\t\t(*) bus_id <int>: identificador de la barra a la que se conecta\n",
    "\t\t(*) name <str>: nombre del generador\n",
    "\t\tCenPgen <float>: energía generada en el instante time [MW]\n",
    "\t\tvalue <float>: mismo valor que CenPgen [MW]\n",
    "\t\t(?) CenCVar <unknown>: parámetro no identificado\n",
    "\t\t(?) CenQgen <unknown>: parámetro no identificado\n",
    "'''\n",
    "def centralscenariofunction(dfcenauxlist, cenpath):\n",
    "    for x in range(ngen):\n",
    "        if indexcen['bus_id'][x] == 0 or np.isnan(indexcen['bus_id'][x]):\n",
    "            continue\n",
    "        aux_df = pd.DataFrame({\n",
    "            'id': indexcen['id'][x],\n",
    "            'time': range(1, time + 1),\n",
    "            'bus_id': int(indexcen['bus_id'][x]),\n",
    "            'name': indexcen['CenName'][x],\n",
    "            'CenPgen': dfcenauxlist[x]['CenPgen'] if len(dfcenauxlist[x]) > 0 else [0]*time,\n",
    "            'value': dfcenauxlist[x]['CenPgen'] if len(dfcenauxlist[x]) > 0 else [0]*time,\n",
    "            'CenCVar': dfcenauxlist[x]['CenCVar'] if len(dfcenauxlist[x]) > 0 else [0]*time,\n",
    "            'CenQgen': dfcenauxlist[x]['CenQgen'] if len(dfcenauxlist[x]) > 0 else [0]*time,\n",
    "        })\n",
    "        aux_df.to_json(cenpath + f\"/central_{indexcen['id'][x]}.json\", orient='records')\n",
    "\n",
    "for hidronum, hidroname in enumerate(hidrolist):\n",
    "    dfcensauxx = plpcen.query(f\"(Hidro=='{hidroname}')\").reset_index()\n",
    "    dfcenlist = [dfcensauxx[dfcensauxx.id == indexcen['id'][x]].reset_index(drop=True) for x in range(ngen)]\n",
    "    print(f\"{((hidronum + 1) / len(hidrolist)) * 100}% Completado\")\n",
    "    centralscenariofunction(dfcenlist, centralscenariolist[hidronum])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.666666666666667% Completado\n",
      "13.333333333333334% Completado\n",
      "20.0% Completado\n",
      "26.666666666666668% Completado\n",
      "33.33333333333333% Completado\n",
      "40.0% Completado\n",
      "46.666666666666664% Completado\n",
      "53.333333333333336% Completado\n",
      "60.0% Completado\n",
      "66.66666666666666% Completado\n",
      "73.33333333333333% Completado\n",
      "80.0% Completado\n",
      "86.66666666666667% Completado\n",
      "93.33333333333333% Completado\n",
      "100.0% Completado\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "        (*) id <int>: identificador de la linea \n",
    "\t\t(*) time <int>: instante de registro\n",
    "\t\t(*) bus_a <int>: identificador de la barra de origen\n",
    "\t\t(*) bus_b <int>: identificador de la barra de destino\n",
    "\t\tflow <float>: flujo en el instante time [MW]\n",
    "\t\tvalue <float>: mismo valor que flow [MW]\n",
    "'''\n",
    "# if not Path('linesscenariolist.pickle').is_file():\n",
    "def linescenariofunction(dflinelist, linpath):\n",
    "    for x in range(nlin):\n",
    "        if linesfinal['active'][x] != 1:\n",
    "            continue\n",
    "        idaux = linesfinal['id'][x]\n",
    "        bus_a_id = linesfinal['bus_a'][x]\n",
    "        bus_b_id = linesfinal['bus_b'][x]\n",
    "        name = linesfinal['LinName'][x]\n",
    "        aux_df = pd.DataFrame({\n",
    "            'id': idaux,\n",
    "            'time': range(1, time + 1),\n",
    "            'name': name,\n",
    "            'bus_a': bus_a_id,\n",
    "            'bus_b': bus_b_id,\n",
    "            'flow': dflinelist[x]['LinFluP'],\n",
    "            'value': dflinelist[x]['LinFluP'],\n",
    "            'capacity': dflinelist[x]['capacity'],\n",
    "        })\n",
    "        aux_df.to_json(linpath + f\"/line_{idaux}.json\", orient='records')\n",
    "\n",
    "for hidronum, hidroname in enumerate(hidrolist):\n",
    "    dflinesaux = plplin.query(f\"(Hidro=='{hidroname}')\").reset_index()\n",
    "    dflinelist = [dflinesaux[dflinesaux.id == linesfinal['id'][x]].reset_index(drop=True) for x in range(nlin)]\n",
    "    print(f\"{((hidronum + 1) / len(hidrolist)) * 100}% Completado\")\n",
    "    linescenariofunction(dflinelist, linescenariolist[hidronum])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.666666666666667% Completado\n",
      "13.333333333333334% Completado\n",
      "20.0% Completado\n",
      "26.666666666666668% Completado\n",
      "33.33333333333333% Completado\n",
      "40.0% Completado\n",
      "46.666666666666664% Completado\n",
      "53.333333333333336% Completado\n",
      "60.0% Completado\n",
      "66.66666666666666% Completado\n",
      "73.33333333333333% Completado\n",
      "80.0% Completado\n",
      "86.66666666666667% Completado\n",
      "93.33333333333333% Completado\n",
      "100.0% Completado\n"
     ]
    }
   ],
   "source": [
    "# Resevoirs contiene:\n",
    "'''\n",
    "\t\t(*) time <int>: instante de registro\n",
    "\t\t(*) id <int>: identificador del embalse\n",
    "\t\t(*) junction_id <int>: identificador del canal al que se conecta\n",
    "\t\t(*) name <str>: nombre del embalse\n",
    "\t\tlevel <float>: nivel en el instante time\n",
    "\t\tvalue <float>: mismo valor que level\n",
    "'''\n",
    "def resscenariofunction(dfreslist, respath):\n",
    "    for x in range(nres):\n",
    "        idaux = indexres['id'][x]\n",
    "        name = indexres['EmbName'][x]\n",
    "        junction_id = junctionsinfo[junctionsinfo['CenName'] == name]['id'].values[0]\n",
    "        aux_df = pd.DataFrame({\n",
    "            'time': range(1, time + 1),\n",
    "            'id': idaux,\n",
    "            'junction_id': junction_id,\n",
    "            'name': name,\n",
    "            'level': (dfreslist[x]['EmbFac'] * dfreslist[x]['EmbVfin']) / 1000000,\n",
    "            'value': (dfreslist[x]['EmbFac'] * dfreslist[x]['EmbVfin']) / 1000000,\n",
    "        })\n",
    "        aux_df.to_json(respath + f\"/reservoir_{idaux}.json\", orient='records')\n",
    "\n",
    "for hidronum, hidroname in enumerate(hidrolist):\n",
    "    dfresaux = reservoirs.query(f\"(Hidro=='{hidroname}')\").reset_index()\n",
    "    dfreslist = [dfresaux[dfresaux.id == indexres['id'][x]].reset_index(drop=True) for x in range(nres)]\n",
    "    print(f\"{((hidronum + 1) / len(hidrolist)) * 100}% Completado\")\n",
    "    resscenariofunction(dfreslist, reservoirscenariolist[hidronum])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topology"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubibar[['latUTM','lonUTM']]=ubibar.apply(lambda row: valorXY(row['latitud'],row['longitud'],scale=0.001),axis=1,result_type='expand')\n",
    "dirdfbus=ubibar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bus electric contiene:\n",
    "'''   \n",
    "\t\t(*) id <int>: identificador de la barra\n",
    "\t\t(*) name <str>: nombre de la barra\n",
    "\t\tlongitude <float>\n",
    "\t\tlatitude <float>\n",
    "\t\tactive <int>: indica si la barra está activa\n",
    "'''\n",
    "auxiliar=[]\n",
    "buselectricfilas_aux=[]\n",
    "for x in range(nbus): # Para cada barra (bus)\n",
    "\tif dirdfbus['BarName'].isin([indexbus['BarName'][x]]).tolist().count(True)>0:\n",
    "\t\tlatitud=float(dirdfbus[dirdfbus['BarName']==indexbus['BarName'][x]]['latitud'].values[0])\n",
    "\t\tlongitud=float(dirdfbus[dirdfbus['BarName']==indexbus['BarName'][x]]['longitud'].values[0])\n",
    "\telse:\n",
    "\t\tauxiliar.append(indexbus['BarName'][x])\n",
    "\t\tlatitud,longitud=aleatory_direction()\n",
    "\taux=[]\n",
    "\taux.append(indexbus['id'][x])\n",
    "\taux.append(indexbus['BarName'][x])\n",
    "\taux.append(longitud)\n",
    "\taux.append(latitud)\n",
    "\taux.append(1)\n",
    "\tbuselectricfilas_aux.append(aux)\n",
    "\n",
    "buselectric=pd.DataFrame(buselectricfilas_aux,columns=['id','name','longitude','latitude','active'])\n",
    "buselectric.to_json(electricTopology+\"/bus.json\",orient='records')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### centrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centrals electric contiene:\n",
    "\n",
    "'''   \n",
    "        (*) id <int>: identificador del generador\n",
    "\t\t(*) bus_id <int>: id de la barra conectada al generador\n",
    "\t\t(*) name <str>: nombre del generador\n",
    "\t\tactive <int>: indica si el generador está activo\n",
    "\t\tcapacity <float>: capacidad del generador [MW]\n",
    "\t\tmin_power <float>: generación mínima [MW]\n",
    "\t\tmax_power <float>: generación máxima [MW]\n",
    "\t\ttype <str>: tipo de generador\n",
    "\t\tlongitude <float>\n",
    "\t\tlatitude <float>\n",
    "\t\t(?) effinciency <float>: Rendimiento [MWh/m3s]\n",
    "\t\t(?) flow <float>: parámetro no identificado\n",
    "\t\t(?) rmin <float>: parámetro no identificado\n",
    "\t\t(?) rmax <float>: parámetro no identificado\n",
    "\t\t(?) cvar <float>: Costo Variable\n",
    "\t\t(?) cvnc <unknown>: parámetro no identificado\n",
    "\t\t(?) cvc <unknown>: parámetro no identificado\n",
    "\t\t(?) entry_date <unknown>: parámetro no identificado\n",
    "'''\n",
    "centralselectricfilas_aux=[]\n",
    "for x in range(ngen): # Para cada generador (central)\n",
    "\tif indexcen['bus_id'][x]==0 or np.isnan(indexcen['bus_id'][x]): # No existe la barra 0, por lo que no se consideran dichos generadores\n",
    "\t\tpass\n",
    "\telse:\n",
    "\t\tlatitud,longitud=None,None\n",
    "\t\taux=[]\n",
    "\t\taux.append(indexcen['id'][x])\n",
    "\t\taux.append(int(indexcen['bus_id'][x]))\n",
    "\t\taux.append(indexcen['CenName'][x])\n",
    "\t\taux.append(1)\n",
    "\t\t# capacidad\n",
    "\t\taux.append(0)\n",
    "\t\taux.append(centralsinfo[centralsinfo['CenName']==indexcen['CenName'][x]]['min_power'])\n",
    "\t\taux.append(centralsinfo[centralsinfo['CenName']==indexcen['CenName'][x]]['max_power'])\n",
    "\t\ttipo=typecentrals[typecentrals['CenName']==indexcen['CenName'][x]]['cen_type'].values\n",
    "\t\tif len(tipo)>0:\n",
    "\t\t\taux.append(tipo[0])\n",
    "\t\telse:\n",
    "\t\t\taux.append(None)\n",
    "\t\taux.append(longitud)\n",
    "\t\taux.append(latitud)\n",
    "\t\taux.append(centralsinfo[centralsinfo['CenName']==indexcen['CenName'][x]]['effinciency'])\n",
    "\t\tfor x in range(7):\n",
    "\t\t\taux.append(0)\n",
    "\t\tcentralselectricfilas_aux.append(aux)\n",
    "\n",
    "centralelectric=pd.DataFrame(centralselectricfilas_aux,columns=['id','bus_id','name','active','capacity','min_power','max_power','type','longitude','latitude','efficiency','flow','rmin','rmax','cvar',\n",
    "'cvnc','cvc','entry_date'])\n",
    "centralelectric.to_json(electricTopology+\"/centrals.json\",orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines electric tiene:\n",
    "'''  \n",
    "        (*) id <int>: identificador de la línea\n",
    "\t\t(*) bus_a <int>: id de la barra origen\n",
    "\t\t(*) bus_b <int>: id de la barra destino\n",
    "\t\tactive <int>: indica si la línea está activa\n",
    "\t\tcapacity <float>: capacidad máxima de la línea [MW]  ->\n",
    "\t\tmax_flow_a_b <float>: flujo máximo en dirección\n",
    "\t\t\t\t\tdispuesta [MW]\n",
    "\t\tmax_flow_b_a <float>: flujo máximo en dirección\n",
    "\t\t\t\t\tcontraria [MW]\n",
    "\t\tvoltage <float>: voltaje de la línea [kV]\n",
    "\t\tr <float>: resistencia de la línea [Ω]\n",
    "\t\tx <float>: reactancia de la línea [Ω]\n",
    "\t\t(? )segments <int>: parámetro no identificado\n",
    "\t\t(?) entry_date <unknown>: parámetro no identificado\n",
    "\t\t(?) exit_date <unknown>: parámetro no identificado\n",
    "'''\n",
    "lineselectricfilas_aux=[]\n",
    "for x in range(nlin): # Para cada linea\n",
    "\tif linesfinal['active'][x]==1:\n",
    "\t\taux=[]\n",
    "\t\tbus_a_id = linesfinal['bus_a'][x]\n",
    "\t\tbus_b_id = linesfinal['bus_b'][x]\n",
    "\t\tname = linesfinal['LinName'][x]\n",
    "\t\taux.append(linesfinal['id'][x])\n",
    "\t\taux.append(name)\n",
    "\t\taux.append(bus_a_id)\n",
    "\t\taux.append(bus_b_id)\n",
    "\t\taux.append(1)\n",
    "\t\t# capacidad\n",
    "\t\taux.append(0)\n",
    "\t\taux.append(linesfinal['max_flow_a_b'][x])\n",
    "\t\taux.append(linesfinal['max_flow_b_a'][x])\n",
    "\t\taux.append(linesfinal['voltage'][x])\n",
    "\t\taux.append(linesfinal['r'][x])\n",
    "\t\taux.append(linesfinal['x'][x])\n",
    "\t\taux.append(linesfinal['segments'][x])\n",
    "\t\taux.append(None)\n",
    "\t\taux.append(None)\n",
    "\t\tlineselectricfilas_aux.append(aux)\n",
    "\n",
    "lineelectric=pd.DataFrame(lineselectricfilas_aux,columns=['id','name','bus_a','bus_b','active','capacity','max_flow_a_b','max_flow_b_a','voltage','r','x','segments','entry_date','exit_date'])\n",
    "lineelectric.to_json(electricTopology+\"/lines.json\",orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''   \n",
    "        (*) id <int>: identificador del embalse\n",
    "\t\t(*) junction_id <int>: id del embalse relacionada (mismo valor id)\n",
    "\t\t(*) name <str>: nombre del embalse\n",
    "\t\t(*) type <str>: tipo de embalse\n",
    "\t\tmin_vol <float>: volumen mínimo del embalse\n",
    "\t\tmax_vol <float>: volumen máximo del embalse\n",
    "\t\tstart_vol <float>: volumen inicial del embalse\n",
    "\t\tend_vol <float>: volumen final del embalse\n",
    "\t\tactive <bool>: indica si el embalse está activo\n",
    "\t\t(?) hyd_independant <bool>: parámetro no identificado\n",
    "\t\t(?) future_cost <unknown>: parámetro no identificado\n",
    "\t\t(?) cmin <unknown>: cota m.s.n.m mínima\n",
    "'''\n",
    "reshydricfilas_aux=[]\n",
    "for x in range(nres): # Para cada linea\n",
    "\taux=[]\n",
    "\tidaux=indexres['id'][x]\n",
    "\tname=indexres['EmbName'][x]\n",
    "\tjunction_id = junctionsinfo[junctionsinfo['CenName']==name]['id'].values[0]\n",
    "\t\n",
    "\taux.append(idaux)\n",
    "\taux.append(junction_id)\n",
    "\taux.append(name)\n",
    "\taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['type'].values[0])\n",
    "\taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['VembMin'].values[0])\n",
    "\taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['VembMax'].values[0])\n",
    "\taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['VembIn'].values[0])\n",
    "\taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['VembFin'].values[0])\n",
    "\taux.append(1)\n",
    "\taux.append(0)\n",
    "\taux.append(None)\n",
    "\taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['cotaMínima'].values[0])\n",
    "\treshydricfilas_aux.append(aux)\n",
    "\n",
    "reshydric=pd.DataFrame(reshydricfilas_aux,columns=['id','junction_id','name','type','min_vol','max_vol','start_vol','end_vol','active','hyd_independant','future_cost','cmin'])\n",
    "reshydric.to_json(hydricTopology+\"/reservoirs.json\",orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Junctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\t(*) id <int>: identificador de la unión\n",
    "\t(*) name <str>: nombre de la unión\n",
    "\tlongitude <float>\n",
    "\tlatitude <float>\n",
    "\tactive <bool>: indica si la barra está activa\n",
    "\tdrainage <bool>: parámetro no identificado\n",
    "'''\n",
    "junctionhydricfilas_aux=[]\n",
    "for x in range(len(junctionsinfo)): # Para cada junction\n",
    "\tlatitud,longitud=aleatory_direction()\n",
    "\taux=[]\n",
    "\taux.append(junctionsinfo['id'][x])\n",
    "\taux.append(junctionsinfo['CenName'][x])\n",
    "\taux.append(longitud)\n",
    "\taux.append(latitud)\n",
    "\taux.append(1)\n",
    "\taux.append(0)\n",
    "\taux.append(junctionsinfo['bus_id'][x])\n",
    "\t\n",
    "\tjunctionhydricfilas_aux.append(aux)\n",
    "\n",
    "junctionhydric=pd.DataFrame(junctionhydricfilas_aux,columns=['id','name','logitude','latitude','active','drainage','bus_id'])\n",
    "junctionhydric.to_json(hydricTopology+\"/junctions.json\",orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waterways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "        (*) id <int>: identificador del canal\n",
    "\t\t(*) name <str>: nombre del canal\n",
    "\t\t(*) type <str>: tipo de waterway\n",
    "\t\t(*) junc_a_id <int>: id de la unión de origen\n",
    "\t\t(*) junc_b_id <int>: id de la unión de destino\n",
    "\t\tactive <bool>: indica si el canal está activo\n",
    "\t\t(?) fmin <unknown>: parámetro no identificado\n",
    "\t\t(?) fmax <unknown>: parámetro no identificado\n",
    "\t\t(?) cvar <unknown>: parámetro no identificado \n",
    "        (?) delay <unknown>: parámetro no identificado\n",
    "'''\n",
    "junctionhydricfilas_aux=[]\n",
    "countid=1\n",
    "for x in range(len(junctionsinfo)):\n",
    "    gen_id=junctionsinfo.serie_hidro_gen[x]\n",
    "    ver_id=junctionsinfo.serie_hidro_ver[x]\n",
    "    name_a = junctionsinfo.CenName[x]\n",
    "    df_adicional = hydric_adicional[hydric_adicional['embalse'] == name_a]\n",
    "    if not pd.isnull(gen_id):\n",
    "        aux=[]\n",
    "        aux.append(countid)\n",
    "        countid+=1\n",
    "        name_b = junctionsinfo[junctionsinfo['id']==gen_id].CenName.values[0]\n",
    "        name = name_a+'_Gen_'+name_b\n",
    "        aux.append(name)\n",
    "        aux.append(\"generation\")\n",
    "        aux.append(junctionsinfo.id[x])\n",
    "        aux.append(gen_id)\n",
    "        aux.append(1)\n",
    "        aux.append(None)\n",
    "        aux.append(None)\n",
    "        aux.append(None)\n",
    "        aux.append(None)\n",
    "        junctionhydricfilas_aux.append(aux)\n",
    "    if not pd.isnull(ver_id):\n",
    "        aux=[]\n",
    "        aux.append(countid)\n",
    "        countid+=1\n",
    "        name_b = junctionsinfo[junctionsinfo['id']==ver_id].CenName.values[0]\n",
    "        name = name_a+'_Vert_'+name_b\n",
    "        aux.append(name)\n",
    "        aux.append(\"spillover\")\n",
    "        aux.append(junctionsinfo.id[x])\n",
    "        aux.append(ver_id)\n",
    "        aux.append(1)\n",
    "        aux.append(None)\n",
    "        aux.append(None)\n",
    "        aux.append(None)\n",
    "        aux.append(None)\n",
    "        junctionhydricfilas_aux.append(aux)\n",
    "    if len(df_adicional)>0:\n",
    "        for i in range(len(df_adicional)):\n",
    "            tipo =df_adicional['type'].iloc[i]\n",
    "            name =\"\"\n",
    "            central = df_adicional['central'].iloc[i].lower()\n",
    "            id_central = centralsinfo[centralsinfo['CenName'].str.lower() == central]['id'].values[0]\n",
    "            aux=[]\n",
    "            aux.append(countid)\n",
    "            countid+=1\n",
    "            name_b = junctionsinfo[junctionsinfo['id']==id_central].CenName.values[0]\n",
    "            if tipo == \"filtration\":\n",
    "                name = name_a+'_Fil_'+name_b\n",
    "            elif tipo == \"extraction\":\n",
    "                name = name_a+'_Ext_'+name_b\n",
    "            aux.append(name)\n",
    "            aux.append(tipo)\n",
    "            aux.append(junctionsinfo.id[x])\n",
    "            aux.append(id_central)\n",
    "            aux.append(1)\n",
    "            aux.append(None)\n",
    "            aux.append(None)\n",
    "            aux.append(None)\n",
    "            aux.append(None)\n",
    "            junctionhydricfilas_aux.append(aux)\n",
    "   \n",
    "waterwayshydric=pd.DataFrame(junctionhydricfilas_aux,columns=[\"id\",\"name\",\"type\",\"junc_a_id\",\"junc_b_id\",\"active\",\"fmin\",\"fmax\",\"cvar\",\"delay\"])\n",
    "waterwayshydric.to_json(hydricTopology+\"/waterways.json\",orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
